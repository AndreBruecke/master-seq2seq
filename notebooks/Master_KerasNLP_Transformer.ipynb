{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W6Q5c99Ibn6h",
    "outputId": "968ccf8d-83af-40f2-bd36-c83ccbf9ef43",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/thesis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fP7ayWracqNh",
    "outputId": "06aa480d-26b4-4be3-fb7c-db2439d246b0",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "# import logging\n",
    "# import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from helper.character_encoder import DictionaryCharacterEncoder\n",
    "from helper.prediction import predict_sequence\n",
    "\n",
    "from implementation.seq2seq.transformer.utils import masked_loss, masked_accuracy\n",
    "from implementation.seq2seq.transformer.keras_nlp import prepare_batches\n",
    "from implementation.seq2seq.transformer.keras_nlp import construct_model_w_teacher_forcing\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras_nlp\n",
    "\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xePXGXM_cWrl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Input file paths\n",
    "# jrc_file = '/thesis/data/jrc_person_pairs.csv'\n",
    "wikidata_file = '/thesis/data/wikidata_person_to_en_norm.csv'\n",
    "\n",
    "model_serialization_path = '/thesis/models/transformer_wikidata_to_en_1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PP58W4r4UVo"
   },
   "source": [
    "## Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "SMRA3no_-amU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "MAX_SEQ_LENGTH = 30  # 40\n",
    "NUM_SAMPLES = 350000\n",
    "VALIDATION_SPLIT = 0.3\n",
    "RANDOM_STATE = 1010\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Model\n",
    "EMBEDDING_DIM = 64\n",
    "INTERMEDIATE_DIM = 512\n",
    "NUM_ENCODER_HEADS = 8\n",
    "NUM_DECODER_HEADS = 8\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 6\n",
    "\n",
    "DROPOUT = 0.2\n",
    "\n",
    "# Training\n",
    "EPOCHS = 60\n",
    "CHECKPOINT_FREQ = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477
    },
    "id": "YklOd1WPIbr2",
    "outputId": "7c097be5-ee6c-4106-c90b-2b11634e8543",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>duglass adamss</td>\n",
       "      <td>douglas adams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>diego velasquez</td>\n",
       "      <td>diego velazquez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>djego velaskess</td>\n",
       "      <td>diego velazquez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>diego velasquez</td>\n",
       "      <td>diego velazquez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>augusto pinocets</td>\n",
       "      <td>augusto pinochet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377875</th>\n",
       "      <td>daniil dushevskiy</td>\n",
       "      <td>daniil duseuski</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377876</th>\n",
       "      <td>daniil dushevskiy</td>\n",
       "      <td>daniil duseuski</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377877</th>\n",
       "      <td>daniil dushevskiy</td>\n",
       "      <td>daniil duseuski</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377878</th>\n",
       "      <td>daniil dushevskiy</td>\n",
       "      <td>daniil duseuski</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377879</th>\n",
       "      <td>vantika agravala</td>\n",
       "      <td>vantika agrawal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>372068 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    input            target\n",
       "0          duglass adamss     douglas adams\n",
       "1         diego velasquez   diego velazquez\n",
       "2         djego velaskess   diego velazquez\n",
       "3         diego velasquez   diego velazquez\n",
       "4        augusto pinocets  augusto pinochet\n",
       "...                   ...               ...\n",
       "377875  daniil dushevskiy   daniil duseuski\n",
       "377876  daniil dushevskiy   daniil duseuski\n",
       "377877  daniil dushevskiy   daniil duseuski\n",
       "377878  daniil dushevskiy   daniil duseuski\n",
       "377879   vantika agravala   vantika agrawal\n",
       "\n",
       "[372068 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pairs_df = pd.read_csv(jrc_file, sep='|', encoding='utf-8')[['input', 'target']]\n",
    "# pairs_df = pairs_df[(pairs_df['input'].str.len() <= MAX_SEQ_LENGTH) & (pairs_df['target'].str.len() <= MAX_SEQ_LENGTH)]\n",
    "# print('Number of JRC pairs:', len(pairs_df))\n",
    "# pairs_df2 = pd.read_csv(wikidata_file, sep='|', encoding='utf-8')[['input', 'target']]\n",
    "# pairs_df2 = pairs_df2[(pairs_df2['input'].str.len() <= MAX_SEQ_LENGTH) & (pairs_df2['target'].str.len() <= MAX_SEQ_LENGTH)]\n",
    "# print('Number of Wikidata pairs:', len(pairs_df2), '\\n')\n",
    "# pairs_df = pd.concat([pairs_df, pairs_df2]).sample(frac=1, random_state=RANDOM_STATE)\n",
    "\n",
    "pairs_df = pd.read_csv(wikidata_file, sep='|', encoding='utf-8')[['input', 'target']]\n",
    "pairs_df = pairs_df[(pairs_df['input'].str.len() <= MAX_SEQ_LENGTH) & (pairs_df['target'].str.len() <= MAX_SEQ_LENGTH)]\n",
    "pairs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "bKGmIus7UwPf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-27 09:21:31.929973: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-27 09:21:31.930228: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-27 09:21:31.930400: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-27 09:21:33.144360: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-27 09:21:33.144609: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-27 09:21:33.144620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-05-27 09:21:33.144761: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-27 09:21:33.144789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9509 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "dce = DictionaryCharacterEncoder(max_seq_length=MAX_SEQ_LENGTH+2)\n",
    "train_batches, val_batches = prepare_batches(pairs_df, dce, NUM_SAMPLES, VALIDATION_SPLIT, BATCH_SIZE, RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OmIgN6LG6yf2",
    "outputId": "32bf90fd-4a8c-4e1f-a58a-383bf2e5b64a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder inputs shape: (64, 30)\n",
      "Decoder inputs shape: (64, 31)\n",
      "Targets shape: (64, 31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-27 09:21:41.715004: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant and shape [245000]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-27 09:21:41.715219: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype variant and shape [245000]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_batches.take(1):\n",
    "    print(f'Encoder inputs shape: {inputs[0].shape}')\n",
    "    print(f'Decoder inputs shape: {inputs[1].shape}')\n",
    "    print(f'Targets shape: {targets.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHdL_iLmSDzu"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "BpByow45PShR"
   },
   "outputs": [],
   "source": [
    "transformer = construct_model_w_teacher_forcing(\n",
    "    num_encoder_layers=NUM_ENCODER_LAYERS, \n",
    "    num_decoder_layers=NUM_DECODER_LAYERS, \n",
    "    unique_tokens=len(dce.charset),\n",
    "    max_seq_length=MAX_SEQ_LENGTH,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    intermediate_dim=INTERMEDIATE_DIM,\n",
    "    encoder_heads=NUM_ENCODER_HEADS,\n",
    "    decoder_heads=NUM_DECODER_HEADS,\n",
    "    dropout=DROPOUT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T3kmpRcNAkwP",
    "outputId": "1c327bc0-0a3a-4dab-f77e-609ced22fa03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer_w_tf\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_inputs (InputLayer)    [(None, 32)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 32, 64)       2176        ['encoder_inputs[0][0]']         \n",
      "                                                                                                  \n",
      " position_embedding (PositionEm  (None, 32, 64)      2048        ['embedding[0][0]']              \n",
      " bedding)                                                                                         \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 32, 64)      0           ['embedding[0][0]',              \n",
      " da)                                                              'position_embedding[0][0]']     \n",
      "                                                                                                  \n",
      " transformer_encoder (Transform  (None, 32, 64)      83008       ['tf.__operators__.add[0][0]']   \n",
      " erEncoder)                                                                                       \n",
      "                                                                                                  \n",
      " transformer_encoder_1 (Transfo  (None, 32, 64)      83008       ['transformer_encoder[0][0]']    \n",
      " rmerEncoder)                                                                                     \n",
      "                                                                                                  \n",
      " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " transformer_encoder_2 (Transfo  (None, 32, 64)      83008       ['transformer_encoder_1[0][0]']  \n",
      " rmerEncoder)                                                                                     \n",
      "                                                                                                  \n",
      " model_1 (Functional)           (None, None, 34)     605090      ['decoder_inputs[0][0]',         \n",
      "                                                                  'transformer_encoder_2[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 858,338\n",
      "Trainable params: 858,338\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer.summary()\n",
    "# transformer.compile(\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "transformer.compile(\n",
    "    loss=masked_loss,\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[masked_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ERhizpGkSJk3"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "cWryJFxCQV1C"
   },
   "outputs": [],
   "source": [
    "steps_per_epoch = len(train_batches)\n",
    "\n",
    "checkpoint_path = f'{model_serialization_path}/checkpoints/' + 'weights-{epoch:03d}'\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "                checkpoint_path, \n",
    "                monitor='val_masked_accuracy', \n",
    "                save_weights_only=True,\n",
    "                save_freq=int(steps_per_epoch * CHECKPOINT_FREQ), \n",
    "                verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nt1YvG8oAn2_",
    "outputId": "72149364-17e7-4d64-eba3-5bd01a3247fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-27 09:21:43.981359: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant and shape [245000]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-27 09:21:43.981565: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype variant and shape [245000]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-05-27 09:21:53.779293: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-05-27 09:21:54.233819: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x67f7350 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-05-27 09:21:54.233845: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2023-05-27 09:21:54.236553: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-05-27 09:21:54.405827: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-05-27 09:21:54.480462: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3829/3829 [==============================] - ETA: 0s - loss: 0.8318 - masked_accuracy: 0.7830"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-27 09:25:06.108870: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant and shape [105000]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-27 09:25:06.109150: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype variant and shape [105000]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3829/3829 [==============================] - 236s 56ms/step - loss: 0.8318 - masked_accuracy: 0.7830 - val_loss: 0.4390 - val_masked_accuracy: 0.8899\n",
      "Epoch 2/60\n",
      "3829/3829 [==============================] - 220s 58ms/step - loss: 0.4598 - masked_accuracy: 0.8842 - val_loss: 0.3795 - val_masked_accuracy: 0.9041\n",
      "Epoch 3/60\n",
      "3829/3829 [==============================] - 213s 56ms/step - loss: 0.4088 - masked_accuracy: 0.8955 - val_loss: 0.3517 - val_masked_accuracy: 0.9100\n",
      "Epoch 4/60\n",
      "3829/3829 [==============================] - 213s 56ms/step - loss: 0.3810 - masked_accuracy: 0.9017 - val_loss: 0.3331 - val_masked_accuracy: 0.9143\n",
      "Epoch 5/60\n",
      "3829/3829 [==============================] - 215s 56ms/step - loss: 0.3633 - masked_accuracy: 0.9056 - val_loss: 0.3173 - val_masked_accuracy: 0.9169\n",
      "Epoch 6/60\n",
      "3829/3829 [==============================] - 214s 56ms/step - loss: 0.3506 - masked_accuracy: 0.9083 - val_loss: 0.3068 - val_masked_accuracy: 0.9188\n",
      "Epoch 7/60\n",
      "3829/3829 [==============================] - 215s 56ms/step - loss: 0.3406 - masked_accuracy: 0.9103 - val_loss: 0.3007 - val_masked_accuracy: 0.9204\n",
      "Epoch 8/60\n",
      "3829/3829 [==============================] - 213s 56ms/step - loss: 0.3326 - masked_accuracy: 0.9120 - val_loss: 0.2959 - val_masked_accuracy: 0.9211\n",
      "Epoch 9/60\n",
      "3829/3829 [==============================] - 213s 55ms/step - loss: 0.3259 - masked_accuracy: 0.9136 - val_loss: 0.2871 - val_masked_accuracy: 0.9233\n",
      "Epoch 10/60\n",
      "3827/3829 [============================>.] - ETA: 0s - loss: 0.3208 - masked_accuracy: 0.9146\n",
      "Epoch 10: saving model to /thesis/models/transformer_wikidata_to_en_1/checkpoints/weights-010\n",
      "3829/3829 [==============================] - 211s 55ms/step - loss: 0.3208 - masked_accuracy: 0.9146 - val_loss: 0.2802 - val_masked_accuracy: 0.9245\n",
      "Epoch 11/60\n",
      "3829/3829 [==============================] - 211s 55ms/step - loss: 0.3159 - masked_accuracy: 0.9156 - val_loss: 0.2778 - val_masked_accuracy: 0.9252\n",
      "Epoch 12/60\n",
      "3829/3829 [==============================] - 214s 56ms/step - loss: 0.3114 - masked_accuracy: 0.9166 - val_loss: 0.2777 - val_masked_accuracy: 0.9247\n",
      "Epoch 13/60\n",
      "3829/3829 [==============================] - 213s 56ms/step - loss: 0.3082 - masked_accuracy: 0.9173 - val_loss: 0.2736 - val_masked_accuracy: 0.9263\n",
      "Epoch 14/60\n",
      "3829/3829 [==============================] - 212s 55ms/step - loss: 0.3047 - masked_accuracy: 0.9181 - val_loss: 0.2722 - val_masked_accuracy: 0.9271\n",
      "Epoch 15/60\n",
      "3829/3829 [==============================] - 210s 55ms/step - loss: 0.3015 - masked_accuracy: 0.9187 - val_loss: 0.2669 - val_masked_accuracy: 0.9280\n",
      "Epoch 16/60\n",
      "3829/3829 [==============================] - 211s 55ms/step - loss: 0.2985 - masked_accuracy: 0.9194 - val_loss: 0.2680 - val_masked_accuracy: 0.9283\n",
      "Epoch 17/60\n",
      "3829/3829 [==============================] - 222s 58ms/step - loss: 0.2961 - masked_accuracy: 0.9199 - val_loss: 0.2655 - val_masked_accuracy: 0.9279\n",
      "Epoch 18/60\n",
      "3829/3829 [==============================] - 214s 56ms/step - loss: 0.2937 - masked_accuracy: 0.9203 - val_loss: 0.2625 - val_masked_accuracy: 0.9290\n",
      "Epoch 19/60\n",
      "3829/3829 [==============================] - 211s 55ms/step - loss: 0.2914 - masked_accuracy: 0.9209 - val_loss: 0.2569 - val_masked_accuracy: 0.9299\n",
      "Epoch 20/60\n",
      "3828/3829 [============================>.] - ETA: 0s - loss: 0.2898 - masked_accuracy: 0.9212\n",
      "Epoch 20: saving model to /thesis/models/transformer_wikidata_to_en_1/checkpoints/weights-020\n",
      "3829/3829 [==============================] - 213s 56ms/step - loss: 0.2898 - masked_accuracy: 0.9211 - val_loss: 0.2572 - val_masked_accuracy: 0.9297\n",
      "Epoch 21/60\n",
      "3829/3829 [==============================] - 210s 55ms/step - loss: 0.2880 - masked_accuracy: 0.9215 - val_loss: 0.2583 - val_masked_accuracy: 0.9299\n",
      "Epoch 22/60\n",
      "3829/3829 [==============================] - 211s 55ms/step - loss: 0.2858 - masked_accuracy: 0.9221 - val_loss: 0.2583 - val_masked_accuracy: 0.9294\n",
      "Epoch 23/60\n",
      "3829/3829 [==============================] - 209s 55ms/step - loss: 0.2843 - masked_accuracy: 0.9223 - val_loss: 0.2524 - val_masked_accuracy: 0.9310\n",
      "Epoch 24/60\n",
      "3829/3829 [==============================] - 210s 55ms/step - loss: 0.2825 - masked_accuracy: 0.9230 - val_loss: 0.2539 - val_masked_accuracy: 0.9310\n",
      "Epoch 25/60\n",
      "3829/3829 [==============================] - 211s 55ms/step - loss: 0.2815 - masked_accuracy: 0.9229 - val_loss: 0.2536 - val_masked_accuracy: 0.9307\n",
      "Epoch 26/60\n",
      "3829/3829 [==============================] - 211s 55ms/step - loss: 0.2801 - masked_accuracy: 0.9233 - val_loss: 0.2499 - val_masked_accuracy: 0.9317\n",
      "Epoch 27/60\n",
      "3829/3829 [==============================] - 213s 56ms/step - loss: 0.2789 - masked_accuracy: 0.9236 - val_loss: 0.2473 - val_masked_accuracy: 0.9322\n",
      "Epoch 28/60\n",
      "3829/3829 [==============================] - 210s 55ms/step - loss: 0.2777 - masked_accuracy: 0.9238 - val_loss: 0.2487 - val_masked_accuracy: 0.9318\n",
      "Epoch 29/60\n",
      "3829/3829 [==============================] - 213s 56ms/step - loss: 0.2767 - masked_accuracy: 0.9240 - val_loss: 0.2482 - val_masked_accuracy: 0.9322\n",
      "Epoch 30/60\n",
      "3828/3829 [============================>.] - ETA: 0s - loss: 0.2752 - masked_accuracy: 0.9243\n",
      "Epoch 30: saving model to /thesis/models/transformer_wikidata_to_en_1/checkpoints/weights-030\n",
      "3829/3829 [==============================] - 210s 55ms/step - loss: 0.2752 - masked_accuracy: 0.9243 - val_loss: 0.2476 - val_masked_accuracy: 0.9323\n",
      "Epoch 31/60\n",
      "3829/3829 [==============================] - 211s 55ms/step - loss: 0.2744 - masked_accuracy: 0.9246 - val_loss: 0.2438 - val_masked_accuracy: 0.9330\n",
      "Epoch 32/60\n",
      "3829/3829 [==============================] - 214s 56ms/step - loss: 0.2732 - masked_accuracy: 0.9248 - val_loss: 0.2467 - val_masked_accuracy: 0.9325\n",
      "Epoch 33/60\n",
      "3829/3829 [==============================] - 210s 55ms/step - loss: 0.2725 - masked_accuracy: 0.9249 - val_loss: 0.2431 - val_masked_accuracy: 0.9329\n",
      "Epoch 34/60\n",
      "3829/3829 [==============================] - 213s 56ms/step - loss: 0.2718 - masked_accuracy: 0.9251 - val_loss: 0.2415 - val_masked_accuracy: 0.9333\n",
      "Epoch 35/60\n",
      "3829/3829 [==============================] - 216s 56ms/step - loss: 0.2706 - masked_accuracy: 0.9254 - val_loss: 0.2432 - val_masked_accuracy: 0.9334\n",
      "Epoch 36/60\n",
      "3829/3829 [==============================] - 211s 55ms/step - loss: 0.2695 - masked_accuracy: 0.9256 - val_loss: 0.2396 - val_masked_accuracy: 0.9339\n",
      "Epoch 37/60\n",
      "3829/3829 [==============================] - 214s 56ms/step - loss: 0.2689 - masked_accuracy: 0.9256 - val_loss: 0.2404 - val_masked_accuracy: 0.9333\n",
      "Epoch 38/60\n",
      "3829/3829 [==============================] - 210s 55ms/step - loss: 0.2681 - masked_accuracy: 0.9260 - val_loss: 0.2384 - val_masked_accuracy: 0.9343\n",
      "Epoch 39/60\n",
      "3829/3829 [==============================] - 212s 55ms/step - loss: 0.2674 - masked_accuracy: 0.9261 - val_loss: 0.2396 - val_masked_accuracy: 0.9341\n",
      "Epoch 40/60\n",
      "3828/3829 [============================>.] - ETA: 0s - loss: 0.2667 - masked_accuracy: 0.9262\n",
      "Epoch 40: saving model to /thesis/models/transformer_wikidata_to_en_1/checkpoints/weights-040\n",
      "3829/3829 [==============================] - 213s 56ms/step - loss: 0.2667 - masked_accuracy: 0.9262 - val_loss: 0.2372 - val_masked_accuracy: 0.9347\n",
      "Epoch 41/60\n",
      "3829/3829 [==============================] - 215s 56ms/step - loss: 0.2658 - masked_accuracy: 0.9264 - val_loss: 0.2371 - val_masked_accuracy: 0.9345\n",
      "Epoch 42/60\n",
      "3829/3829 [==============================] - 208s 54ms/step - loss: 0.2649 - masked_accuracy: 0.9265 - val_loss: 0.2403 - val_masked_accuracy: 0.9340\n",
      "Epoch 43/60\n",
      "3829/3829 [==============================] - 210s 55ms/step - loss: 0.2643 - masked_accuracy: 0.9266 - val_loss: 0.2401 - val_masked_accuracy: 0.9338\n",
      "Epoch 44/60\n",
      "3829/3829 [==============================] - 218s 57ms/step - loss: 0.2642 - masked_accuracy: 0.9269 - val_loss: 0.2376 - val_masked_accuracy: 0.9344\n",
      "Epoch 45/60\n",
      "3829/3829 [==============================] - 211s 55ms/step - loss: 0.2635 - masked_accuracy: 0.9269 - val_loss: 0.2366 - val_masked_accuracy: 0.9348\n",
      "Epoch 46/60\n",
      "3829/3829 [==============================] - 213s 56ms/step - loss: 0.2628 - masked_accuracy: 0.9272 - val_loss: 0.2359 - val_masked_accuracy: 0.9346\n",
      "Epoch 47/60\n",
      "3829/3829 [==============================] - 211s 55ms/step - loss: 0.2623 - masked_accuracy: 0.9271 - val_loss: 0.2378 - val_masked_accuracy: 0.9350\n",
      "Epoch 48/60\n",
      "3829/3829 [==============================] - 212s 55ms/step - loss: 0.2616 - masked_accuracy: 0.9274 - val_loss: 0.2403 - val_masked_accuracy: 0.9346\n",
      "Epoch 49/60\n",
      "3829/3829 [==============================] - 214s 56ms/step - loss: 0.2609 - masked_accuracy: 0.9275 - val_loss: 0.2334 - val_masked_accuracy: 0.9355\n",
      "Epoch 50/60\n",
      "3828/3829 [============================>.] - ETA: 0s - loss: 0.2606 - masked_accuracy: 0.9276\n",
      "Epoch 50: saving model to /thesis/models/transformer_wikidata_to_en_1/checkpoints/weights-050\n",
      "3829/3829 [==============================] - 212s 55ms/step - loss: 0.2606 - masked_accuracy: 0.9276 - val_loss: 0.2342 - val_masked_accuracy: 0.9351\n",
      "Epoch 51/60\n",
      "3829/3829 [==============================] - 213s 56ms/step - loss: 0.2600 - masked_accuracy: 0.9277 - val_loss: 0.2363 - val_masked_accuracy: 0.9345\n",
      "Epoch 52/60\n",
      "3829/3829 [==============================] - 212s 55ms/step - loss: 0.2595 - masked_accuracy: 0.9277 - val_loss: 0.2325 - val_masked_accuracy: 0.9358\n",
      "Epoch 53/60\n",
      "3829/3829 [==============================] - 213s 56ms/step - loss: 0.2593 - masked_accuracy: 0.9279 - val_loss: 0.2342 - val_masked_accuracy: 0.9355\n",
      "Epoch 54/60\n",
      "3829/3829 [==============================] - 213s 56ms/step - loss: 0.2581 - masked_accuracy: 0.9281 - val_loss: 0.2335 - val_masked_accuracy: 0.9356\n",
      "Epoch 55/60\n",
      "3829/3829 [==============================] - 211s 55ms/step - loss: 0.2580 - masked_accuracy: 0.9280 - val_loss: 0.2345 - val_masked_accuracy: 0.9358\n",
      "Epoch 56/60\n",
      "3829/3829 [==============================] - 212s 55ms/step - loss: 0.2572 - masked_accuracy: 0.9283 - val_loss: 0.2355 - val_masked_accuracy: 0.9353\n",
      "Epoch 57/60\n",
      "3829/3829 [==============================] - 211s 55ms/step - loss: 0.2569 - masked_accuracy: 0.9284 - val_loss: 0.2314 - val_masked_accuracy: 0.9360\n",
      "Epoch 58/60\n",
      "3829/3829 [==============================] - 212s 55ms/step - loss: 0.2564 - masked_accuracy: 0.9285 - val_loss: 0.2318 - val_masked_accuracy: 0.9362\n",
      "Epoch 59/60\n",
      "3829/3829 [==============================] - 215s 56ms/step - loss: 0.2564 - masked_accuracy: 0.9285 - val_loss: 0.2325 - val_masked_accuracy: 0.9355\n",
      "Epoch 60/60\n",
      "3827/3829 [============================>.] - ETA: 0s - loss: 0.2560 - masked_accuracy: 0.9286\n",
      "Epoch 60: saving model to /thesis/models/transformer_wikidata_to_en_1/checkpoints/weights-060\n",
      "3829/3829 [==============================] - 212s 55ms/step - loss: 0.2560 - masked_accuracy: 0.9286 - val_loss: 0.2297 - val_masked_accuracy: 0.9363\n"
     ]
    }
   ],
   "source": [
    "history = transformer.fit(train_batches, epochs=EPOCHS, validation_data=val_batches, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mquhrVPYRMhY",
    "outputId": "8c253fb1-a777-46dc-d85d-876a8ffaefa3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-27 12:54:42.466387: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-27 12:54:42.476337: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-27 12:54:42.485923: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-27 12:54:42.495676: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-27 12:54:42.505164: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-27 12:54:42.515794: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-27 12:54:42.526141: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-27 12:54:42.537450: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-27 12:54:42.549157: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-27 12:54:42.560372: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-27 12:54:42.571384: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-27 12:54:42.583211: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-27 12:54:42.593087: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-27 12:54:42.598683: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-27 12:54:43.273079: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,32,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-27 12:54:45.782106: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,32,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-27 12:54:47.293182: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-27 12:54:47.307825: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-27 12:54:47.316974: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-27 12:54:47.458356: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-27 12:54:47.466660: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-27 12:54:47.611834: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-27 12:54:47.620985: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-27 12:54:47.761585: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-27 12:54:47.770941: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-27 12:54:47.919344: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-27 12:54:47.929128: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-27 12:54:48.078676: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-27 12:54:48.088599: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-27 12:54:48.236476: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,64]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as multi_head_attention_layer_call_fn, multi_head_attention_layer_call_and_return_conditional_losses, layer_normalization_layer_call_fn, layer_normalization_layer_call_and_return_conditional_losses, dropout_1_layer_call_fn while saving (showing 5 of 342). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /thesis/models/transformer_wikidata_to_en_1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /thesis/models/transformer_wikidata_to_en_1/assets\n"
     ]
    }
   ],
   "source": [
    "transformer.save(f'{model_serialization_path}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "eVenfcXpVDXs"
   },
   "outputs": [],
   "source": [
    "with open(model_serialization_path + '/train_history.p', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)\n",
    "\n",
    "train_config = {\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'epochs': EPOCHS,\n",
    "    'num_samples': NUM_SAMPLES,\n",
    "    'max_seq_length': MAX_SEQ_LENGTH,\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'validation_split': VALIDATION_SPLIT,\n",
    "    'encoder_layers': NUM_ENCODER_LAYERS,\n",
    "    'decoder_layers': NUM_DECODER_LAYERS,\n",
    "    'encoder_heads': NUM_ENCODER_HEADS,\n",
    "    'decoder_heads': NUM_DECODER_HEADS,\n",
    "    'dropout': DROPOUT,\n",
    "    'embedding_dim': EMBEDDING_DIM,\n",
    "    'intermediate_dim': INTERMEDIATE_DIM\n",
    "}\n",
    "\n",
    "with open(model_serialization_path + '/config.p', 'wb') as file_pi:\n",
    "    pickle.dump(train_config, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "3P4ZZWOi9Hl_"
   },
   "outputs": [],
   "source": [
    "transformer = tf.keras.models.load_model(f'{model_serialization_path}/', custom_objects={'masked_loss': masked_loss, 'masked_accuracy': masked_accuracy})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMBywO57SNO8"
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vTCtzqJWElIR",
    "outputId": "b9a2bc41-949b-40a4-ad6d-f357009f13c4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samuel meyer\n",
      "sam meyer\n",
      "\n",
      "dmitry medvedev\n",
      "dmitri medvedev\n",
      "\n",
      "paulo ricardo\n",
      "paul ricardo\n",
      "\n",
      "zouheir al qaissi\n",
      "zuheir al-qaissi\n",
      "\n",
      "tarek al bichri\n",
      "tarek al-bichri\n",
      "\n",
      "thorsten brotzmann\n",
      "thorsten broetzmann\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def decode_sequences(input_sentence):\n",
    "     # Tokenize the encoder input.\n",
    "    encoder_input_tokens = tf.keras.utils.pad_sequences(\n",
    "        dce.to_ids([input_sentence], insert_markers=True), \n",
    "        padding='post', \n",
    "        maxlen=MAX_SEQ_LENGTH+2\n",
    "    )\n",
    "\n",
    "    # Define a function that outputs the next token's probability given the\n",
    "    # input sequence.\n",
    "    def token_probability_fn(decoder_input_tokens):\n",
    "        return transformer([encoder_input_tokens, decoder_input_tokens])[:, -1, :]\n",
    "\n",
    "\n",
    "    prompt = tf.fill((1, 1), dce.char_index['\\t'])\n",
    "    generated_tokens = keras_nlp.utils.top_p_search(\n",
    "        token_probability_fn,\n",
    "        prompt,\n",
    "        p=0.1,\n",
    "        max_length=MAX_SEQ_LENGTH,\n",
    "        end_token_id=dce.char_index['\\n'],\n",
    "    )\n",
    "    generated_sentences = ''.join([dce.inverse_char_index[tkn] for tkn in generated_tokens.numpy()[0]])\n",
    "    return generated_sentences.strip()\n",
    "\n",
    "names = [\n",
    "    'samuel meyer',\n",
    "    'dmitry medvedev',\n",
    "    'paulo ricardo',\n",
    "    'zouheir al qaissi',\n",
    "    'tarek al bichri',\n",
    "    'thorsten brotzmann'\n",
    "]\n",
    "\n",
    "for s in names:\n",
    "    translated = decode_sequences(s)\n",
    "    print(s)\n",
    "    print(translated)\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "224e0c0e73d638a3e6069c377694d7b3b3236453c6483b31fd1a6425297d86e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
