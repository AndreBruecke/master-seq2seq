{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W6Q5c99Ibn6h",
    "outputId": "968ccf8d-83af-40f2-bd36-c83ccbf9ef43",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/thesis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fP7ayWracqNh",
    "outputId": "06aa480d-26b4-4be3-fb7c-db2439d246b0",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "# import logging\n",
    "# import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from helper.character_encoder import DictionaryCharacterEncoder\n",
    "from helper.prediction import predict_sequence\n",
    "\n",
    "from implementation.seq2seq.transformer.utils import masked_loss, masked_accuracy\n",
    "from implementation.seq2seq.transformer.keras_nlp import prepare_batches\n",
    "from implementation.seq2seq.transformer.keras_nlp import construct_model_w_teacher_forcing\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras_nlp\n",
    "\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "xePXGXM_cWrl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Input file paths\n",
    "# jrc_file = '/thesis/data/jrc_person_pairs.csv'\n",
    "# wikidata_file = '/thesis/data/wikidata_person_to_en_norm.csv'\n",
    "wikidata_file = '/thesis/data/experiments/org_train_val_e1.csv'\n",
    "\n",
    "model_serialization_path = '/thesis/models/e1_mixed_org'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PP58W4r4UVo"
   },
   "source": [
    "## Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "SMRA3no_-amU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "MAX_SEQ_LENGTH = 60\n",
    "NUM_SAMPLES = 500000 # 350000\n",
    "VALIDATION_SPLIT = 0.25\n",
    "RANDOM_STATE = 1010\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# Model\n",
    "EMBEDDING_DIM = 128\n",
    "INTERMEDIATE_DIM = 1024\n",
    "NUM_ENCODER_HEADS = 4\n",
    "NUM_DECODER_HEADS = 4\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 6\n",
    "\n",
    "DROPOUT = 0.2\n",
    "\n",
    "# Training\n",
    "EPOCHS = 60\n",
    "CHECKPOINT_FREQ = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477
    },
    "id": "YklOd1WPIbr2",
    "outputId": "7c097be5-ee6c-4106-c90b-2b11634e8543",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sabmiller</td>\n",
       "      <td>sabmiller plc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sabmiller plc</td>\n",
       "      <td>sabmiller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>international astronomical union</td>\n",
       "      <td>den internasjonale astronomiske union</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>international astronomical union</td>\n",
       "      <td>union astronomique internationale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>international astronomical union</td>\n",
       "      <td>internationale astronomische union</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523583</th>\n",
       "      <td>mundial 2010</td>\n",
       "      <td>mistrovstvi sveta ve fotbale 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523584</th>\n",
       "      <td>sveuciliste u sydneyu</td>\n",
       "      <td>universidade de sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523585</th>\n",
       "      <td>palestiense staot</td>\n",
       "      <td>palastinensische autonomiebehorde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523586</th>\n",
       "      <td>europaischem stabilitatsmechanismus</td>\n",
       "      <td>europaischen stabilitatsmechanismus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523587</th>\n",
       "      <td>ezedin al qassam</td>\n",
       "      <td>ezzeddin al qassam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>514167 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      input   \n",
       "0                                 sabmiller  \\\n",
       "1                             sabmiller plc   \n",
       "2          international astronomical union   \n",
       "3          international astronomical union   \n",
       "4          international astronomical union   \n",
       "...                                     ...   \n",
       "523583                         mundial 2010   \n",
       "523584                sveuciliste u sydneyu   \n",
       "523585                    palestiense staot   \n",
       "523586  europaischem stabilitatsmechanismus   \n",
       "523587                     ezedin al qassam   \n",
       "\n",
       "                                       target  \n",
       "0                               sabmiller plc  \n",
       "1                                   sabmiller  \n",
       "2       den internasjonale astronomiske union  \n",
       "3           union astronomique internationale  \n",
       "4          internationale astronomische union  \n",
       "...                                       ...  \n",
       "523583      mistrovstvi sveta ve fotbale 2010  \n",
       "523584                 universidade de sydney  \n",
       "523585      palastinensische autonomiebehorde  \n",
       "523586    europaischen stabilitatsmechanismus  \n",
       "523587                     ezzeddin al qassam  \n",
       "\n",
       "[514167 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pairs_df = pd.read_csv(jrc_file, sep='|', encoding='utf-8')[['input', 'target']]\n",
    "# pairs_df = pairs_df[(pairs_df['input'].str.len() <= MAX_SEQ_LENGTH) & (pairs_df['target'].str.len() <= MAX_SEQ_LENGTH)]\n",
    "# print('Number of JRC pairs:', len(pairs_df))\n",
    "# pairs_df2 = pd.read_csv(wikidata_file, sep='|', encoding='utf-8')[['input', 'target']]\n",
    "# pairs_df2 = pairs_df2[(pairs_df2['input'].str.len() <= MAX_SEQ_LENGTH) & (pairs_df2['target'].str.len() <= MAX_SEQ_LENGTH)]\n",
    "# print('Number of Wikidata pairs:', len(pairs_df2), '\\n')\n",
    "# pairs_df = pd.concat([pairs_df, pairs_df2]).sample(frac=1, random_state=RANDOM_STATE)\n",
    "\n",
    "pairs_df = pd.read_csv(wikidata_file, sep='|', encoding='utf-8')[['input', 'target']]\n",
    "pairs_df = pairs_df[(pairs_df['input'].str.len() <= MAX_SEQ_LENGTH) & (pairs_df['target'].str.len() <= MAX_SEQ_LENGTH)]\n",
    "pairs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "bKGmIus7UwPf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-31 15:37:57.769877: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-31 15:37:57.770226: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-31 15:37:57.770457: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-31 15:37:58.310386: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-31 15:37:58.310676: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-31 15:37:58.310691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-08-31 15:37:58.310828: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-31 15:37:58.310854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9509 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "dce = DictionaryCharacterEncoder(max_seq_length=MAX_SEQ_LENGTH+2, charset='extended')\n",
    "train_batches, val_batches = prepare_batches(pairs_df, dce, NUM_SAMPLES, VALIDATION_SPLIT, BATCH_SIZE, RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OmIgN6LG6yf2",
    "outputId": "32bf90fd-4a8c-4e1f-a58a-383bf2e5b64a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder inputs shape: (128, 57)\n",
      "Decoder inputs shape: (128, 54)\n",
      "Targets shape: (128, 54)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-31 15:38:16.452986: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype variant and shape [375000]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-08-31 15:38:16.453210: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype variant and shape [375000]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_batches.take(1):\n",
    "    print(f'Encoder inputs shape: {inputs[0].shape}')\n",
    "    print(f'Decoder inputs shape: {inputs[1].shape}')\n",
    "    print(f'Targets shape: {targets.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHdL_iLmSDzu"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "BpByow45PShR"
   },
   "outputs": [],
   "source": [
    "transformer = construct_model_w_teacher_forcing(\n",
    "    num_encoder_layers=NUM_ENCODER_LAYERS, \n",
    "    num_decoder_layers=NUM_DECODER_LAYERS, \n",
    "    unique_tokens=len(dce.charset),\n",
    "    max_seq_length=MAX_SEQ_LENGTH,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    intermediate_dim=INTERMEDIATE_DIM,\n",
    "    encoder_heads=NUM_ENCODER_HEADS,\n",
    "    decoder_heads=NUM_DECODER_HEADS,\n",
    "    dropout=DROPOUT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T3kmpRcNAkwP",
    "outputId": "1c327bc0-0a3a-4dab-f77e-609ced22fa03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer_w_tf\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_inputs (InputLayer)    [(None, 62)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 62, 128)      5888        ['encoder_inputs[0][0]']         \n",
      "                                                                                                  \n",
      " position_embedding (PositionEm  (None, 62, 128)     7936        ['embedding[0][0]']              \n",
      " bedding)                                                                                         \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 62, 128)     0           ['embedding[0][0]',              \n",
      " da)                                                              'position_embedding[0][0]']     \n",
      "                                                                                                  \n",
      " transformer_encoder (Transform  (None, 62, 128)     329856      ['tf.__operators__.add[0][0]']   \n",
      " erEncoder)                                                                                       \n",
      "                                                                                                  \n",
      " transformer_encoder_1 (Transfo  (None, 62, 128)     329856      ['transformer_encoder[0][0]']    \n",
      " rmerEncoder)                                                                                     \n",
      "                                                                                                  \n",
      " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " transformer_encoder_2 (Transfo  (None, 62, 128)     329856      ['transformer_encoder_1[0][0]']  \n",
      " rmerEncoder)                                                                                     \n",
      "                                                                                                  \n",
      " model_1 (Functional)           (None, None, 46)     2396718     ['decoder_inputs[0][0]',         \n",
      "                                                                  'transformer_encoder_2[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,400,110\n",
      "Trainable params: 3,400,110\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer.summary()\n",
    "# transformer.compile(\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "transformer.compile(\n",
    "    loss=masked_loss,\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[masked_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ERhizpGkSJk3"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "cWryJFxCQV1C"
   },
   "outputs": [],
   "source": [
    "steps_per_epoch = len(train_batches)\n",
    "\n",
    "checkpoint_path = f'{model_serialization_path}/checkpoints/' + 'weights-{epoch:03d}'\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "                checkpoint_path, \n",
    "                monitor='val_masked_accuracy', \n",
    "                save_weights_only=True,\n",
    "                save_freq=int(steps_per_epoch * CHECKPOINT_FREQ), \n",
    "                verbose=1)\n",
    "\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_masked_accuracy', patience=3, min_delta=0.0015, mode='max', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nt1YvG8oAn2_",
    "outputId": "72149364-17e7-4d64-eba3-5bd01a3247fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-31 15:38:18.253654: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype variant and shape [375000]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-08-31 15:38:18.253869: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant and shape [375000]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-08-31 15:38:28.571841: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-08-31 15:38:28.803396: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x8c2ba00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-08-31 15:38:28.803422: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2023-08-31 15:38:28.806682: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-08-31 15:38:28.920442: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-08-31 15:38:28.998920: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2930/2930 [==============================] - ETA: 0s - loss: 1.8048 - masked_accuracy: 0.4686"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-31 15:47:03.501534: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant and shape [125000]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-08-31 15:47:03.501799: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant and shape [125000]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2930/2930 [==============================] - 589s 194ms/step - loss: 1.8048 - masked_accuracy: 0.4686 - val_loss: 1.1315 - val_masked_accuracy: 0.6723\n",
      "Epoch 2/60\n",
      "2930/2930 [==============================] - 564s 193ms/step - loss: 1.1336 - masked_accuracy: 0.6690 - val_loss: 0.8997 - val_masked_accuracy: 0.7367\n",
      "Epoch 3/60\n",
      "2930/2930 [==============================] - 558s 191ms/step - loss: 0.9904 - masked_accuracy: 0.7086 - val_loss: 0.8212 - val_masked_accuracy: 0.7590\n",
      "Epoch 4/60\n",
      "2930/2930 [==============================] - 561s 192ms/step - loss: 0.9189 - masked_accuracy: 0.7281 - val_loss: 0.7482 - val_masked_accuracy: 0.7788\n",
      "Epoch 5/60\n",
      "2930/2930 [==============================] - 562s 192ms/step - loss: 0.8720 - masked_accuracy: 0.7411 - val_loss: 0.7135 - val_masked_accuracy: 0.7886\n",
      "Epoch 6/60\n",
      "2930/2930 [==============================] - 563s 192ms/step - loss: 0.8372 - masked_accuracy: 0.7507 - val_loss: 0.6766 - val_masked_accuracy: 0.7987\n",
      "Epoch 7/60\n",
      "2930/2930 [==============================] - 560s 191ms/step - loss: 0.8087 - masked_accuracy: 0.7585 - val_loss: 0.6566 - val_masked_accuracy: 0.8043\n",
      "Epoch 8/60\n",
      "2930/2930 [==============================] - 562s 192ms/step - loss: 0.7852 - masked_accuracy: 0.7649 - val_loss: 0.6274 - val_masked_accuracy: 0.8120\n",
      "Epoch 9/60\n",
      "2930/2930 [==============================] - 562s 192ms/step - loss: 0.7658 - masked_accuracy: 0.7702 - val_loss: 0.6138 - val_masked_accuracy: 0.8158\n",
      "Epoch 10/60\n",
      "2929/2930 [============================>.] - ETA: 0s - loss: 0.7493 - masked_accuracy: 0.7749\n",
      "Epoch 10: saving model to /thesis/models/e1_mixed_org/checkpoints/weights-010\n",
      "2930/2930 [==============================] - 562s 192ms/step - loss: 0.7493 - masked_accuracy: 0.7749 - val_loss: 0.6017 - val_masked_accuracy: 0.8192\n",
      "Epoch 11/60\n",
      "2930/2930 [==============================] - 561s 192ms/step - loss: 0.7348 - masked_accuracy: 0.7787 - val_loss: 0.5897 - val_masked_accuracy: 0.8232\n",
      "Epoch 12/60\n",
      "2930/2930 [==============================] - 562s 192ms/step - loss: 0.7219 - masked_accuracy: 0.7823 - val_loss: 0.5787 - val_masked_accuracy: 0.8262\n",
      "Epoch 13/60\n",
      "2930/2930 [==============================] - 562s 192ms/step - loss: 0.7101 - masked_accuracy: 0.7857 - val_loss: 0.5698 - val_masked_accuracy: 0.8287\n",
      "Epoch 14/60\n",
      "2930/2930 [==============================] - 560s 191ms/step - loss: 0.6996 - masked_accuracy: 0.7886 - val_loss: 0.5583 - val_masked_accuracy: 0.8309\n",
      "Epoch 15/60\n",
      "2930/2930 [==============================] - 563s 192ms/step - loss: 0.6900 - masked_accuracy: 0.7913 - val_loss: 0.5513 - val_masked_accuracy: 0.8331\n",
      "Epoch 16/60\n",
      "2930/2930 [==============================] - 562s 192ms/step - loss: 0.6810 - masked_accuracy: 0.7936 - val_loss: 0.5432 - val_masked_accuracy: 0.8357\n",
      "Epoch 17/60\n",
      "2930/2930 [==============================] - 561s 191ms/step - loss: 0.6732 - masked_accuracy: 0.7958 - val_loss: 0.5382 - val_masked_accuracy: 0.8368\n",
      "Epoch 18/60\n",
      "2930/2930 [==============================] - 561s 192ms/step - loss: 0.6650 - masked_accuracy: 0.7980 - val_loss: 0.5325 - val_masked_accuracy: 0.8385\n",
      "Epoch 19/60\n",
      "2930/2930 [==============================] - 562s 192ms/step - loss: 0.6585 - masked_accuracy: 0.8000 - val_loss: 0.5232 - val_masked_accuracy: 0.8408\n",
      "Epoch 20/60\n",
      "2929/2930 [============================>.] - ETA: 0s - loss: 0.6515 - masked_accuracy: 0.8019\n",
      "Epoch 20: saving model to /thesis/models/e1_mixed_org/checkpoints/weights-020\n",
      "2930/2930 [==============================] - 562s 192ms/step - loss: 0.6515 - masked_accuracy: 0.8019 - val_loss: 0.5208 - val_masked_accuracy: 0.8420\n",
      "Epoch 21/60\n",
      "2930/2930 [==============================] - 562s 192ms/step - loss: 0.6454 - masked_accuracy: 0.8035 - val_loss: 0.5141 - val_masked_accuracy: 0.8438\n",
      "Epoch 22/60\n",
      "2930/2930 [==============================] - 563s 192ms/step - loss: 0.6387 - masked_accuracy: 0.8054 - val_loss: 0.5095 - val_masked_accuracy: 0.8454\n",
      "Epoch 23/60\n",
      "2930/2930 [==============================] - 562s 192ms/step - loss: 0.6333 - masked_accuracy: 0.8071 - val_loss: 0.5052 - val_masked_accuracy: 0.8470\n",
      "Epoch 24/60\n",
      "2930/2930 [==============================] - 562s 192ms/step - loss: 0.6277 - masked_accuracy: 0.8085 - val_loss: 0.5000 - val_masked_accuracy: 0.8481\n",
      "Epoch 25/60\n",
      "2930/2930 [==============================] - 562s 192ms/step - loss: 0.6232 - masked_accuracy: 0.8099 - val_loss: 0.4980 - val_masked_accuracy: 0.8487\n",
      "Epoch 26/60\n",
      "2930/2930 [==============================] - 561s 191ms/step - loss: 0.6184 - masked_accuracy: 0.8111 - val_loss: 0.4919 - val_masked_accuracy: 0.8501\n",
      "Epoch 27/60\n",
      "2930/2930 [==============================] - 562s 192ms/step - loss: 0.6131 - masked_accuracy: 0.8126 - val_loss: 0.4904 - val_masked_accuracy: 0.8507\n",
      "Epoch 28/60\n",
      "2930/2930 [==============================] - 562s 192ms/step - loss: 0.6094 - masked_accuracy: 0.8139 - val_loss: 0.4862 - val_masked_accuracy: 0.8512\n",
      "Epoch 29/60\n",
      "2930/2930 [==============================] - 562s 192ms/step - loss: 0.6054 - masked_accuracy: 0.8148 - val_loss: 0.4789 - val_masked_accuracy: 0.8535\n",
      "Epoch 30/60\n",
      "2929/2930 [============================>.] - ETA: 0s - loss: 0.6006 - masked_accuracy: 0.8160\n",
      "Epoch 30: saving model to /thesis/models/e1_mixed_org/checkpoints/weights-030\n",
      "2930/2930 [==============================] - 563s 192ms/step - loss: 0.6007 - masked_accuracy: 0.8160 - val_loss: 0.4805 - val_masked_accuracy: 0.8531\n",
      "Epoch 31/60\n",
      "2930/2930 [==============================] - 563s 192ms/step - loss: 0.5973 - masked_accuracy: 0.8171 - val_loss: 0.4712 - val_masked_accuracy: 0.8557\n",
      "Epoch 32/60\n",
      "2930/2930 [==============================] - 563s 192ms/step - loss: 0.5938 - masked_accuracy: 0.8180 - val_loss: 0.4758 - val_masked_accuracy: 0.8545\n",
      "Epoch 33/60\n",
      "2930/2930 [==============================] - 563s 192ms/step - loss: 0.5895 - masked_accuracy: 0.8192 - val_loss: 0.4742 - val_masked_accuracy: 0.8556\n",
      "Epoch 34/60\n",
      "2930/2930 [==============================] - 561s 191ms/step - loss: 0.5868 - masked_accuracy: 0.8201 - val_loss: 0.4678 - val_masked_accuracy: 0.8566\n"
     ]
    }
   ],
   "source": [
    "history = transformer.fit(train_batches, epochs=EPOCHS, validation_data=val_batches, callbacks=[checkpoint, es_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mquhrVPYRMhY",
    "outputId": "8c253fb1-a777-46dc-d85d-876a8ffaefa3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-31 20:57:13.084750: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-08-31 20:57:13.095902: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-08-31 20:57:13.107214: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-08-31 20:57:13.119225: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-08-31 20:57:13.131013: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-08-31 20:57:13.144200: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-08-31 20:57:13.155943: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-08-31 20:57:13.169142: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-08-31 20:57:13.180458: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-08-31 20:57:13.193273: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-08-31 20:57:13.204902: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-08-31 20:57:13.217798: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-08-31 20:57:13.229597: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-08-31 20:57:13.234775: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-08-31 20:57:13.984923: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,62,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-08-31 20:57:16.390218: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,62,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-08-31 20:57:18.084832: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-08-31 20:57:18.100001: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-08-31 20:57:18.109022: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-08-31 20:57:18.253393: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-08-31 20:57:18.262835: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-08-31 20:57:18.415626: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-08-31 20:57:18.426159: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-08-31 20:57:18.572716: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-08-31 20:57:18.582445: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-08-31 20:57:18.729996: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-08-31 20:57:18.739471: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-08-31 20:57:18.884238: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-08-31 20:57:18.893821: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-08-31 20:57:19.039163: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,128]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as multi_head_attention_layer_call_fn, multi_head_attention_layer_call_and_return_conditional_losses, layer_normalization_layer_call_fn, layer_normalization_layer_call_and_return_conditional_losses, dropout_1_layer_call_fn while saving (showing 5 of 342). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /thesis/models/e1_mixed_org/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /thesis/models/e1_mixed_org/assets\n"
     ]
    }
   ],
   "source": [
    "transformer.save(f'{model_serialization_path}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "eVenfcXpVDXs"
   },
   "outputs": [],
   "source": [
    "with open(model_serialization_path + '/train_history.p', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)\n",
    "\n",
    "train_config = {\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'epochs': EPOCHS,\n",
    "    'num_samples': NUM_SAMPLES,\n",
    "    'max_seq_length': MAX_SEQ_LENGTH,\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'validation_split': VALIDATION_SPLIT,\n",
    "    'encoder_layers': NUM_ENCODER_LAYERS,\n",
    "    'decoder_layers': NUM_DECODER_LAYERS,\n",
    "    'encoder_heads': NUM_ENCODER_HEADS,\n",
    "    'decoder_heads': NUM_DECODER_HEADS,\n",
    "    'dropout': DROPOUT,\n",
    "    'embedding_dim': EMBEDDING_DIM,\n",
    "    'intermediate_dim': INTERMEDIATE_DIM\n",
    "}\n",
    "\n",
    "with open(model_serialization_path + '/config.p', 'wb') as file_pi:\n",
    "    pickle.dump(train_config, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "3P4ZZWOi9Hl_"
   },
   "outputs": [],
   "source": [
    "transformer = tf.keras.models.load_model(f'{model_serialization_path}/', custom_objects={'masked_loss': masked_loss, 'masked_accuracy': masked_accuracy})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMBywO57SNO8"
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vTCtzqJWElIR",
    "outputId": "b9a2bc41-949b-40a4-ad6d-f357009f13c4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samuel meyer\n",
      "samuel meyer group\n",
      "\n",
      "dmitry medvedev\n",
      "dmitry medvedev\n",
      "\n",
      "paulo ricardo\n",
      "paulo ricardo\n",
      "\n",
      "zouheir al qaissi\n",
      "al qaissi\n",
      "\n",
      "tarek al bichri\n",
      "tarek al bichri\n",
      "\n",
      "thorsten brotzmann\n",
      "thorsten brotzmann\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def decode_sequences(input_sentence):\n",
    "     # Tokenize the encoder input.\n",
    "    encoder_input_tokens = tf.keras.utils.pad_sequences(\n",
    "        dce.to_ids([input_sentence], insert_markers=True), \n",
    "        padding='post', \n",
    "        maxlen=MAX_SEQ_LENGTH+2\n",
    "    )\n",
    "\n",
    "    # Define a function that outputs the next token's probability given the\n",
    "    # input sequence.\n",
    "    def token_probability_fn(decoder_input_tokens):\n",
    "        return transformer([encoder_input_tokens, decoder_input_tokens])[:, -1, :]\n",
    "\n",
    "\n",
    "    prompt = tf.fill((1, 1), dce.char_index['\\t'])\n",
    "    generated_tokens = keras_nlp.utils.top_p_search(\n",
    "        token_probability_fn,\n",
    "        prompt,\n",
    "        p=0.1,\n",
    "        max_length=MAX_SEQ_LENGTH,\n",
    "        end_token_id=dce.char_index['\\n'],\n",
    "    )\n",
    "    generated_sentences = ''.join([dce.inverse_char_index[tkn] for tkn in generated_tokens.numpy()[0]])\n",
    "    return generated_sentences.strip()\n",
    "\n",
    "names = [\n",
    "    'samuel meyer',\n",
    "    'dmitry medvedev',\n",
    "    'paulo ricardo',\n",
    "    'zouheir al qaissi',\n",
    "    'tarek al bichri',\n",
    "    'thorsten brotzmann'\n",
    "]\n",
    "\n",
    "for s in names:\n",
    "    translated = decode_sequences(s)\n",
    "    print(s)\n",
    "    print(translated)\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "224e0c0e73d638a3e6069c377694d7b3b3236453c6483b31fd1a6425297d86e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
