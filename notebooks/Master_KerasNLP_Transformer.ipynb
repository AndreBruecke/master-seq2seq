{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W6Q5c99Ibn6h",
    "outputId": "968ccf8d-83af-40f2-bd36-c83ccbf9ef43",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/thesis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fP7ayWracqNh",
    "outputId": "06aa480d-26b4-4be3-fb7c-db2439d246b0",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "# import logging\n",
    "# import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from helper.character_encoder import DictionaryCharacterEncoder\n",
    "from helper.prediction import predict_sequence\n",
    "\n",
    "from implementation.seq2seq.transformer.utils import masked_loss, masked_accuracy\n",
    "from implementation.seq2seq.transformer.keras_nlp import prepare_batches\n",
    "from implementation.seq2seq.transformer.keras_nlp import construct_model_w_teacher_forcing\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras_nlp\n",
    "\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xePXGXM_cWrl"
   },
   "outputs": [],
   "source": [
    "# Input file paths\n",
    "jrc_file = '/thesis/data/jrc_person_pairs.csv'\n",
    "wikidata_file = '/thesis/data/wikidata_person_pairs.csv'\n",
    "\n",
    "model_serialization_path = '/thesis/models/transformer_mixed_kerasnlp_1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PP58W4r4UVo"
   },
   "source": [
    "## Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "SMRA3no_-amU"
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "MAX_SEQ_LENGTH = 30  # 40\n",
    "NUM_SAMPLES = 550000\n",
    "VALIDATION_SPLIT = 0.3\n",
    "RANDOM_STATE = 1010\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Model\n",
    "EMBEDDING_DIM = 64\n",
    "INTERMEDIATE_DIM = 512\n",
    "NUM_ENCODER_HEADS = 8\n",
    "NUM_DECODER_HEADS = 8\n",
    "NUM_ENCODER_LAYERS = 2\n",
    "NUM_DECODER_LAYERS = 4\n",
    "\n",
    "DROPOUT = 0.2\n",
    "\n",
    "# Training\n",
    "EPOCHS = 60\n",
    "CHECKPOINT_FREQ = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477
    },
    "id": "YklOd1WPIbr2",
    "outputId": "7c097be5-ee6c-4106-c90b-2b11634e8543"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of JRC pairs: 131636\n",
      "Number of Wikidata pairs: 434230 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>272102</th>\n",
       "      <td>katharine mccook knox</td>\n",
       "      <td>katherine mccook knox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431611</th>\n",
       "      <td>meri aroni</td>\n",
       "      <td>mary aroni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61867</th>\n",
       "      <td>alejandro foxley</td>\n",
       "      <td>alejandre foxley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424660</th>\n",
       "      <td>niche perez</td>\n",
       "      <td>limber perez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244085</th>\n",
       "      <td>jindrich wankel</td>\n",
       "      <td>heinrich wankel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440185</th>\n",
       "      <td>vitaly lisakovich</td>\n",
       "      <td>vital' lisakovic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122954</th>\n",
       "      <td>adam vojtech</td>\n",
       "      <td>adama vojtecha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27211</th>\n",
       "      <td>david petraeus</td>\n",
       "      <td>david petreaeus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164783</th>\n",
       "      <td>ethel standiford-mehling</td>\n",
       "      <td>ethel standiford-mehlingan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108526</th>\n",
       "      <td>magdalen herbert</td>\n",
       "      <td>magdalen newport</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>565866 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           input                      target\n",
       "272102     katharine mccook knox       katherine mccook knox\n",
       "431611                meri aroni                  mary aroni\n",
       "61867           alejandro foxley            alejandre foxley\n",
       "424660               niche perez                limber perez\n",
       "244085           jindrich wankel             heinrich wankel\n",
       "...                          ...                         ...\n",
       "440185         vitaly lisakovich            vital' lisakovic\n",
       "122954              adam vojtech              adama vojtecha\n",
       "27211             david petraeus             david petreaeus\n",
       "164783  ethel standiford-mehling  ethel standiford-mehlingan\n",
       "108526          magdalen herbert            magdalen newport\n",
       "\n",
       "[565866 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_df = pd.read_csv(jrc_file, sep='|', encoding='utf-8')[['input', 'target']]\n",
    "pairs_df = pairs_df[(pairs_df['input'].str.len() <= MAX_SEQ_LENGTH) & (pairs_df['target'].str.len() <= MAX_SEQ_LENGTH)]\n",
    "print('Number of JRC pairs:', len(pairs_df))\n",
    "pairs_df2 = pd.read_csv(wikidata_file, sep='|', encoding='utf-8')[['input', 'target']]\n",
    "pairs_df2 = pairs_df2[(pairs_df2['input'].str.len() <= MAX_SEQ_LENGTH) & (pairs_df2['target'].str.len() <= MAX_SEQ_LENGTH)]\n",
    "print('Number of Wikidata pairs:', len(pairs_df2), '\\n')\n",
    "\n",
    "pairs_df = pd.concat([pairs_df, pairs_df2]).sample(frac=1, random_state=RANDOM_STATE)\n",
    "pairs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "bKGmIus7UwPf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 09:50:28.034541: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-13 09:50:28.034848: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-13 09:50:28.035028: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-13 09:50:28.660148: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-13 09:50:28.660329: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-13 09:50:28.660338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-05-13 09:50:28.660440: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-13 09:50:28.660464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9509 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "dce = DictionaryCharacterEncoder(max_seq_length=MAX_SEQ_LENGTH+2)\n",
    "train_batches, val_batches = prepare_batches(pairs_df, dce, NUM_SAMPLES, VALIDATION_SPLIT, BATCH_SIZE, RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OmIgN6LG6yf2",
    "outputId": "32bf90fd-4a8c-4e1f-a58a-383bf2e5b64a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder inputs shape: (64, 32)\n",
      "Decoder inputs shape: (64, 29)\n",
      "Targets shape: (64, 29)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 09:50:40.904273: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype variant and shape [334150]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-05-13 09:50:40.904614: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype variant and shape [334150]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_batches.take(1):\n",
    "    print(f'Encoder inputs shape: {inputs[0].shape}')\n",
    "    print(f'Decoder inputs shape: {inputs[1].shape}')\n",
    "    print(f'Targets shape: {targets.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHdL_iLmSDzu"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "BpByow45PShR"
   },
   "outputs": [],
   "source": [
    "transformer = construct_model_w_teacher_forcing(\n",
    "    num_encoder_layers=NUM_ENCODER_LAYERS, \n",
    "    num_decoder_layers=NUM_DECODER_LAYERS, \n",
    "    unique_tokens=len(dce.charset),\n",
    "    max_seq_length=MAX_SEQ_LENGTH,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    intermediate_dim=INTERMEDIATE_DIM,\n",
    "    encoder_heads=NUM_ENCODER_HEADS,\n",
    "    decoder_heads=NUM_DECODER_HEADS,\n",
    "    dropout=DROPOUT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T3kmpRcNAkwP",
    "outputId": "1c327bc0-0a3a-4dab-f77e-609ced22fa03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer_w_tf\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_inputs (InputLayer)    [(None, 32)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 32, 64)       2176        ['encoder_inputs[0][0]']         \n",
      "                                                                                                  \n",
      " position_embedding (PositionEm  (None, 32, 64)      2048        ['embedding[0][0]']              \n",
      " bedding)                                                                                         \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 32, 64)      0           ['embedding[0][0]',              \n",
      " da)                                                              'position_embedding[0][0]']     \n",
      "                                                                                                  \n",
      " transformer_encoder (Transform  (None, 32, 64)      83008       ['tf.__operators__.add[0][0]']   \n",
      " erEncoder)                                                                                       \n",
      "                                                                                                  \n",
      " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " transformer_encoder_1 (Transfo  (None, 32, 64)      83008       ['transformer_encoder[0][0]']    \n",
      " rmerEncoder)                                                                                     \n",
      "                                                                                                  \n",
      " model_1 (Functional)           (None, None, 34)     405538      ['decoder_inputs[0][0]',         \n",
      "                                                                  'transformer_encoder_1[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 575,778\n",
      "Trainable params: 575,778\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer.summary()\n",
    "# transformer.compile(\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "transformer.compile(\n",
    "    loss=masked_loss,\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[masked_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ERhizpGkSJk3"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "cWryJFxCQV1C"
   },
   "outputs": [],
   "source": [
    "steps_per_epoch = len(train_batches)\n",
    "\n",
    "checkpoint_path = f'{model_serialization_path}/checkpoints/' + 'weights-{epoch:03d}'\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "                checkpoint_path, \n",
    "                monitor='val_masked_accuracy', \n",
    "                save_weights_only=True,\n",
    "                save_freq=int(steps_per_epoch * CHECKPOINT_FREQ), \n",
    "                verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nt1YvG8oAn2_",
    "outputId": "72149364-17e7-4d64-eba3-5bd01a3247fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 09:50:42.827978: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype variant and shape [334150]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-05-13 09:50:42.828174: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant and shape [334150]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-13 09:50:49.819832: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-05-13 09:50:50.253416: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f10683483c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-05-13 09:50:50.253444: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2023-05-13 09:50:50.256009: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-05-13 09:50:50.380723: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-05-13 09:50:50.452325: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5222/5222 [==============================] - ETA: 0s - loss: 0.9275 - masked_accuracy: 0.7655"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 09:53:56.101583: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype variant and shape [165000]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-05-13 09:53:56.102120: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype variant and shape [165000]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5222/5222 [==============================] - 233s 42ms/step - loss: 0.9275 - masked_accuracy: 0.7655 - val_loss: 0.6136 - val_masked_accuracy: 0.8456\n",
      "Epoch 2/60\n",
      "5222/5222 [==============================] - 213s 41ms/step - loss: 0.6423 - masked_accuracy: 0.8368 - val_loss: 0.5589 - val_masked_accuracy: 0.8554\n",
      "Epoch 3/60\n",
      "5222/5222 [==============================] - 213s 41ms/step - loss: 0.5989 - masked_accuracy: 0.8454 - val_loss: 0.5309 - val_masked_accuracy: 0.8608\n",
      "Epoch 4/60\n",
      "5222/5222 [==============================] - 216s 41ms/step - loss: 0.5746 - masked_accuracy: 0.8501 - val_loss: 0.5138 - val_masked_accuracy: 0.8647\n",
      "Epoch 5/60\n",
      "5222/5222 [==============================] - 214s 41ms/step - loss: 0.5581 - masked_accuracy: 0.8532 - val_loss: 0.5014 - val_masked_accuracy: 0.8664\n",
      "Epoch 6/60\n",
      "5222/5222 [==============================] - 216s 41ms/step - loss: 0.5466 - masked_accuracy: 0.8556 - val_loss: 0.4963 - val_masked_accuracy: 0.8683\n",
      "Epoch 7/60\n",
      "5222/5222 [==============================] - 211s 40ms/step - loss: 0.5370 - masked_accuracy: 0.8574 - val_loss: 0.4803 - val_masked_accuracy: 0.8706\n",
      "Epoch 8/60\n",
      "5222/5222 [==============================] - 211s 40ms/step - loss: 0.5297 - masked_accuracy: 0.8589 - val_loss: 0.4738 - val_masked_accuracy: 0.8723\n",
      "Epoch 9/60\n",
      "5222/5222 [==============================] - 211s 40ms/step - loss: 0.5237 - masked_accuracy: 0.8602 - val_loss: 0.4714 - val_masked_accuracy: 0.8723\n",
      "Epoch 10/60\n",
      "5221/5222 [============================>.] - ETA: 0s - loss: 0.5183 - masked_accuracy: 0.8613\n",
      "Epoch 10: saving model to /thesis/models/transformer_mixed_kerasnlp_1/checkpoints/weights-010\n",
      "5222/5222 [==============================] - 211s 40ms/step - loss: 0.5183 - masked_accuracy: 0.8613 - val_loss: 0.4640 - val_masked_accuracy: 0.8738\n",
      "Epoch 11/60\n",
      "5222/5222 [==============================] - 213s 41ms/step - loss: 0.5142 - masked_accuracy: 0.8623 - val_loss: 0.4636 - val_masked_accuracy: 0.8746\n",
      "Epoch 12/60\n",
      "5222/5222 [==============================] - 208s 40ms/step - loss: 0.5102 - masked_accuracy: 0.8630 - val_loss: 0.4625 - val_masked_accuracy: 0.8751\n",
      "Epoch 13/60\n",
      "5222/5222 [==============================] - 209s 40ms/step - loss: 0.5072 - masked_accuracy: 0.8637 - val_loss: 0.4537 - val_masked_accuracy: 0.8760\n",
      "Epoch 14/60\n",
      "5222/5222 [==============================] - 208s 40ms/step - loss: 0.5043 - masked_accuracy: 0.8642 - val_loss: 0.4548 - val_masked_accuracy: 0.8760\n",
      "Epoch 15/60\n",
      "5222/5222 [==============================] - 210s 40ms/step - loss: 0.5017 - masked_accuracy: 0.8646 - val_loss: 0.4544 - val_masked_accuracy: 0.8763\n",
      "Epoch 16/60\n",
      "5222/5222 [==============================] - 210s 40ms/step - loss: 0.4990 - masked_accuracy: 0.8653 - val_loss: 0.4514 - val_masked_accuracy: 0.8771\n",
      "Epoch 17/60\n",
      "5222/5222 [==============================] - 204s 39ms/step - loss: 0.4970 - masked_accuracy: 0.8657 - val_loss: 0.4473 - val_masked_accuracy: 0.8776\n",
      "Epoch 18/60\n",
      "5222/5222 [==============================] - 211s 40ms/step - loss: 0.4952 - masked_accuracy: 0.8661 - val_loss: 0.4495 - val_masked_accuracy: 0.8775\n",
      "Epoch 19/60\n",
      "5222/5222 [==============================] - 208s 40ms/step - loss: 0.4931 - masked_accuracy: 0.8666 - val_loss: 0.4477 - val_masked_accuracy: 0.8779\n",
      "Epoch 20/60\n",
      "5221/5222 [============================>.] - ETA: 0s - loss: 0.4918 - masked_accuracy: 0.8668\n",
      "Epoch 20: saving model to /thesis/models/transformer_mixed_kerasnlp_1/checkpoints/weights-020\n",
      "5222/5222 [==============================] - 210s 40ms/step - loss: 0.4918 - masked_accuracy: 0.8668 - val_loss: 0.4429 - val_masked_accuracy: 0.8787\n",
      "Epoch 21/60\n",
      "5222/5222 [==============================] - 210s 40ms/step - loss: 0.4899 - masked_accuracy: 0.8672 - val_loss: 0.4435 - val_masked_accuracy: 0.8787\n",
      "Epoch 22/60\n",
      "5222/5222 [==============================] - 207s 40ms/step - loss: 0.4887 - masked_accuracy: 0.8676 - val_loss: 0.4394 - val_masked_accuracy: 0.8787\n",
      "Epoch 23/60\n",
      "5222/5222 [==============================] - 209s 40ms/step - loss: 0.4877 - masked_accuracy: 0.8678 - val_loss: 0.4422 - val_masked_accuracy: 0.8785\n",
      "Epoch 24/60\n",
      "5222/5222 [==============================] - 210s 40ms/step - loss: 0.4861 - masked_accuracy: 0.8680 - val_loss: 0.4373 - val_masked_accuracy: 0.8800\n",
      "Epoch 25/60\n",
      "5222/5222 [==============================] - 207s 40ms/step - loss: 0.4851 - masked_accuracy: 0.8683 - val_loss: 0.4367 - val_masked_accuracy: 0.8799\n",
      "Epoch 26/60\n",
      "5222/5222 [==============================] - 206s 39ms/step - loss: 0.4842 - masked_accuracy: 0.8684 - val_loss: 0.4365 - val_masked_accuracy: 0.8800\n",
      "Epoch 27/60\n",
      "5222/5222 [==============================] - 207s 40ms/step - loss: 0.4831 - masked_accuracy: 0.8687 - val_loss: 0.4372 - val_masked_accuracy: 0.8799\n",
      "Epoch 28/60\n",
      "5222/5222 [==============================] - 208s 40ms/step - loss: 0.4819 - masked_accuracy: 0.8690 - val_loss: 0.4368 - val_masked_accuracy: 0.8801\n",
      "Epoch 29/60\n",
      "5222/5222 [==============================] - 206s 39ms/step - loss: 0.4814 - masked_accuracy: 0.8691 - val_loss: 0.4354 - val_masked_accuracy: 0.8806\n",
      "Epoch 30/60\n",
      "5221/5222 [============================>.] - ETA: 0s - loss: 0.4803 - masked_accuracy: 0.8693\n",
      "Epoch 30: saving model to /thesis/models/transformer_mixed_kerasnlp_1/checkpoints/weights-030\n",
      "5222/5222 [==============================] - 204s 39ms/step - loss: 0.4803 - masked_accuracy: 0.8693 - val_loss: 0.4345 - val_masked_accuracy: 0.8810\n",
      "Epoch 31/60\n",
      "5222/5222 [==============================] - 205s 39ms/step - loss: 0.4799 - masked_accuracy: 0.8694 - val_loss: 0.4353 - val_masked_accuracy: 0.8802\n",
      "Epoch 32/60\n",
      "5222/5222 [==============================] - 207s 40ms/step - loss: 0.4789 - masked_accuracy: 0.8696 - val_loss: 0.4333 - val_masked_accuracy: 0.8798\n",
      "Epoch 33/60\n",
      "5222/5222 [==============================] - 206s 39ms/step - loss: 0.4783 - masked_accuracy: 0.8697 - val_loss: 0.4334 - val_masked_accuracy: 0.8804\n",
      "Epoch 34/60\n",
      "5222/5222 [==============================] - 209s 40ms/step - loss: 0.4774 - masked_accuracy: 0.8699 - val_loss: 0.4326 - val_masked_accuracy: 0.8807\n",
      "Epoch 35/60\n",
      "5222/5222 [==============================] - 209s 40ms/step - loss: 0.4770 - masked_accuracy: 0.8699 - val_loss: 0.4339 - val_masked_accuracy: 0.8807\n",
      "Epoch 36/60\n",
      "5222/5222 [==============================] - 209s 40ms/step - loss: 0.4764 - masked_accuracy: 0.8702 - val_loss: 0.4321 - val_masked_accuracy: 0.8810\n",
      "Epoch 37/60\n",
      "5222/5222 [==============================] - 211s 40ms/step - loss: 0.4757 - masked_accuracy: 0.8703 - val_loss: 0.4298 - val_masked_accuracy: 0.8811\n",
      "Epoch 38/60\n",
      "5222/5222 [==============================] - 210s 40ms/step - loss: 0.4749 - masked_accuracy: 0.8705 - val_loss: 0.4276 - val_masked_accuracy: 0.8818\n",
      "Epoch 39/60\n",
      "5222/5222 [==============================] - 209s 40ms/step - loss: 0.4746 - masked_accuracy: 0.8706 - val_loss: 0.4320 - val_masked_accuracy: 0.8807\n",
      "Epoch 40/60\n",
      "5220/5222 [============================>.] - ETA: 0s - loss: 0.4738 - masked_accuracy: 0.8707\n",
      "Epoch 40: saving model to /thesis/models/transformer_mixed_kerasnlp_1/checkpoints/weights-040\n",
      "5222/5222 [==============================] - 212s 41ms/step - loss: 0.4738 - masked_accuracy: 0.8707 - val_loss: 0.4310 - val_masked_accuracy: 0.8818\n",
      "Epoch 41/60\n",
      "5222/5222 [==============================] - 207s 40ms/step - loss: 0.4736 - masked_accuracy: 0.8709 - val_loss: 0.4306 - val_masked_accuracy: 0.8810\n",
      "Epoch 42/60\n",
      "5222/5222 [==============================] - 210s 40ms/step - loss: 0.4731 - masked_accuracy: 0.8709 - val_loss: 0.4293 - val_masked_accuracy: 0.8818\n",
      "Epoch 43/60\n",
      "5222/5222 [==============================] - 212s 41ms/step - loss: 0.4723 - masked_accuracy: 0.8711 - val_loss: 0.4312 - val_masked_accuracy: 0.8809\n",
      "Epoch 44/60\n",
      "5222/5222 [==============================] - 210s 40ms/step - loss: 0.4722 - masked_accuracy: 0.8710 - val_loss: 0.4297 - val_masked_accuracy: 0.8812\n",
      "Epoch 45/60\n",
      "5222/5222 [==============================] - 207s 40ms/step - loss: 0.4716 - masked_accuracy: 0.8712 - val_loss: 0.4249 - val_masked_accuracy: 0.8821\n",
      "Epoch 46/60\n",
      "5222/5222 [==============================] - 209s 40ms/step - loss: 0.4712 - masked_accuracy: 0.8713 - val_loss: 0.4296 - val_masked_accuracy: 0.8817\n",
      "Epoch 47/60\n",
      "5222/5222 [==============================] - 211s 40ms/step - loss: 0.4711 - masked_accuracy: 0.8713 - val_loss: 0.4313 - val_masked_accuracy: 0.8815\n",
      "Epoch 48/60\n",
      "5222/5222 [==============================] - 208s 40ms/step - loss: 0.4704 - masked_accuracy: 0.8714 - val_loss: 0.4278 - val_masked_accuracy: 0.8824\n",
      "Epoch 49/60\n",
      "5222/5222 [==============================] - 213s 41ms/step - loss: 0.4700 - masked_accuracy: 0.8715 - val_loss: 0.4247 - val_masked_accuracy: 0.8822\n",
      "Epoch 50/60\n",
      "5220/5222 [============================>.] - ETA: 0s - loss: 0.4698 - masked_accuracy: 0.8715\n",
      "Epoch 50: saving model to /thesis/models/transformer_mixed_kerasnlp_1/checkpoints/weights-050\n",
      "5222/5222 [==============================] - 210s 40ms/step - loss: 0.4698 - masked_accuracy: 0.8715 - val_loss: 0.4282 - val_masked_accuracy: 0.8811\n",
      "Epoch 51/60\n",
      "5222/5222 [==============================] - 207s 40ms/step - loss: 0.4695 - masked_accuracy: 0.8717 - val_loss: 0.4270 - val_masked_accuracy: 0.8815\n",
      "Epoch 52/60\n",
      "5222/5222 [==============================] - 206s 40ms/step - loss: 0.4691 - masked_accuracy: 0.8717 - val_loss: 0.4245 - val_masked_accuracy: 0.8827\n",
      "Epoch 53/60\n",
      "5222/5222 [==============================] - 207s 40ms/step - loss: 0.4686 - masked_accuracy: 0.8720 - val_loss: 0.4263 - val_masked_accuracy: 0.8818\n",
      "Epoch 54/60\n",
      "5222/5222 [==============================] - 205s 39ms/step - loss: 0.4685 - masked_accuracy: 0.8719 - val_loss: 0.4255 - val_masked_accuracy: 0.8815\n",
      "Epoch 55/60\n",
      "5222/5222 [==============================] - 205s 39ms/step - loss: 0.4681 - masked_accuracy: 0.8721 - val_loss: 0.4234 - val_masked_accuracy: 0.8829\n",
      "Epoch 56/60\n",
      "5222/5222 [==============================] - 206s 39ms/step - loss: 0.4679 - masked_accuracy: 0.8720 - val_loss: 0.4243 - val_masked_accuracy: 0.8827\n",
      "Epoch 57/60\n",
      "5222/5222 [==============================] - 207s 40ms/step - loss: 0.4674 - masked_accuracy: 0.8722 - val_loss: 0.4247 - val_masked_accuracy: 0.8828\n",
      "Epoch 58/60\n",
      "5222/5222 [==============================] - 207s 40ms/step - loss: 0.4672 - masked_accuracy: 0.8722 - val_loss: 0.4238 - val_masked_accuracy: 0.8830\n",
      "Epoch 59/60\n",
      "5222/5222 [==============================] - 204s 39ms/step - loss: 0.4671 - masked_accuracy: 0.8723 - val_loss: 0.4224 - val_masked_accuracy: 0.8832\n",
      "Epoch 60/60\n",
      "5221/5222 [============================>.] - ETA: 0s - loss: 0.4669 - masked_accuracy: 0.8723\n",
      "Epoch 60: saving model to /thesis/models/transformer_mixed_kerasnlp_1/checkpoints/weights-060\n",
      "5222/5222 [==============================] - 206s 39ms/step - loss: 0.4669 - masked_accuracy: 0.8723 - val_loss: 0.4229 - val_masked_accuracy: 0.8822\n"
     ]
    }
   ],
   "source": [
    "history = transformer.fit(train_batches, epochs=EPOCHS, validation_data=val_batches, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mquhrVPYRMhY",
    "outputId": "8c253fb1-a777-46dc-d85d-876a8ffaefa3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 13:20:04.436445: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-13 13:20:04.445815: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-13 13:20:04.457185: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-13 13:20:04.467543: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-13 13:20:04.478274: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-13 13:20:04.493892: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-13 13:20:04.503645: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-13 13:20:04.514958: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-13 13:20:04.525801: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-13 13:20:04.530837: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-13 13:20:05.116687: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,32,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-13 13:20:06.538844: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,32,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-13 13:20:07.492726: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-13 13:20:07.507725: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-13 13:20:07.518051: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-13 13:20:07.657057: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-13 13:20:07.667542: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-13 13:20:07.808903: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-13 13:20:07.817660: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-13 13:20:07.964682: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-13 13:20:07.974484: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,64]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-13 13:20:08.117918: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,64]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as multi_head_attention_layer_call_fn, multi_head_attention_layer_call_and_return_conditional_losses, layer_normalization_layer_call_fn, layer_normalization_layer_call_and_return_conditional_losses, dropout_1_layer_call_fn while saving (showing 5 of 228). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /thesis/models/transformer_mixed_kerasnlp_1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /thesis/models/transformer_mixed_kerasnlp_1/assets\n"
     ]
    }
   ],
   "source": [
    "transformer.save(f'{model_serialization_path}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "eVenfcXpVDXs"
   },
   "outputs": [],
   "source": [
    "with open(model_serialization_path + '/train_history.p', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)\n",
    "\n",
    "train_config = {\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'epochs': EPOCHS,\n",
    "    'num_samples': NUM_SAMPLES,\n",
    "    'max_seq_length': MAX_SEQ_LENGTH,\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'validation_split': VALIDATION_SPLIT,\n",
    "    'encoder_layers': NUM_ENCODER_LAYERS,\n",
    "    'decoder_layers': NUM_DECODER_LAYERS,\n",
    "    'encoder_heads': NUM_ENCODER_HEADS,\n",
    "    'decoder_heads': NUM_DECODER_HEADS,\n",
    "    'dropout': DROPOUT,\n",
    "    'embedding_dim': EMBEDDING_DIM,\n",
    "    'intermediate_dim': INTERMEDIATE_DIM\n",
    "}\n",
    "\n",
    "with open(model_serialization_path + '/config.p', 'wb') as file_pi:\n",
    "    pickle.dump(train_config, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "3P4ZZWOi9Hl_"
   },
   "outputs": [],
   "source": [
    "transformer = tf.keras.models.load_model(f'{model_serialization_path}/', custom_objects={'masked_loss': masked_loss, 'masked_accuracy': masked_accuracy})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMBywO57SNO8"
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vTCtzqJWElIR",
    "outputId": "b9a2bc41-949b-40a4-ad6d-f357009f13c4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samuel meyer\n",
      "samuel meyerova\n",
      "\n",
      "dmitry medvedev\n",
      "dmitrij medvedev\n",
      "\n",
      "paulo ricardo\n",
      "paulo ricardi\n",
      "\n",
      "zouheir al qaissi\n",
      "zuheir al qaissi\n",
      "\n",
      "tarek al bichri\n",
      "tarek al bichry\n",
      "\n",
      "thorsten brotzmann\n",
      "thorsten brotzman\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def decode_sequences(input_sentence):\n",
    "     # Tokenize the encoder input.\n",
    "    encoder_input_tokens = tf.keras.utils.pad_sequences(\n",
    "        dce.to_ids([input_sentence], insert_markers=True), \n",
    "        padding='post', \n",
    "        maxlen=MAX_SEQ_LENGTH+2\n",
    "    )\n",
    "\n",
    "    # Define a function that outputs the next token's probability given the\n",
    "    # input sequence.\n",
    "    def token_probability_fn(decoder_input_tokens):\n",
    "        return transformer([encoder_input_tokens, decoder_input_tokens])[:, -1, :]\n",
    "\n",
    "\n",
    "    prompt = tf.fill((1, 1), dce.char_index['\\t'])\n",
    "    generated_tokens = keras_nlp.utils.top_p_search(\n",
    "        token_probability_fn,\n",
    "        prompt,\n",
    "        p=0.1,\n",
    "        max_length=MAX_SEQ_LENGTH,\n",
    "        end_token_id=dce.char_index['\\n'],\n",
    "    )\n",
    "    generated_sentences = ''.join([dce.inverse_char_index[tkn] for tkn in generated_tokens.numpy()[0]])\n",
    "    return generated_sentences.strip()\n",
    "\n",
    "names = [\n",
    "    'samuel meyer',\n",
    "    'dmitry medvedev',\n",
    "    'paulo ricardo',\n",
    "    'zouheir al qaissi',\n",
    "    'tarek al bichri',\n",
    "    'thorsten brotzmann'\n",
    "]\n",
    "\n",
    "for s in names:\n",
    "    translated = decode_sequences(s)\n",
    "    print(s)\n",
    "    print(translated)\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "224e0c0e73d638a3e6069c377694d7b3b3236453c6483b31fd1a6425297d86e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
