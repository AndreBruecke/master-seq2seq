{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W6Q5c99Ibn6h",
    "outputId": "968ccf8d-83af-40f2-bd36-c83ccbf9ef43",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/thesis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fP7ayWracqNh",
    "outputId": "06aa480d-26b4-4be3-fb7c-db2439d246b0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-28 10:18:25.792478: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-28 10:18:25.819618: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-28 10:18:26.972019: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-28 10:18:26.975928: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-28 10:18:26.976184: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "# import logging\n",
    "# import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from helper.character_encoder import DictionaryCharacterEncoder\n",
    "from helper.prediction import predict_sequence\n",
    "\n",
    "from implementation.seq2seq.transformer.utils import masked_loss, masked_accuracy\n",
    "from implementation.seq2seq.transformer.keras_nlp import prepare_asymmetric_batches\n",
    "from implementation.seq2seq.transformer.keras_nlp import construct_asymmetric_model_w_teacher_forcing\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras_nlp\n",
    "\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "xePXGXM_cWrl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Input file paths\n",
    "# jrc_file = '/thesis/data/jrc_person_pairs.csv'\n",
    "wikidata_file = '/thesis/data/wikidata_person_variant_list_norm.csv'\n",
    "\n",
    "model_serialization_path = '/thesis/models/transformer_wikidata_variant_list_1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PP58W4r4UVo"
   },
   "source": [
    "## Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SMRA3no_-amU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "MAX_ENCODER_SEQ_LENGTH = 30\n",
    "MAX_DECODER_SEQ_LENGTH = 120\n",
    "NUM_SAMPLES = 500000\n",
    "VALIDATION_SPLIT = 0.3\n",
    "RANDOM_STATE = 1010\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Model\n",
    "EMBEDDING_DIM = 128\n",
    "INTERMEDIATE_DIM = 512\n",
    "NUM_ENCODER_HEADS = 8\n",
    "NUM_DECODER_HEADS = 8\n",
    "NUM_ENCODER_LAYERS = 2\n",
    "NUM_DECODER_LAYERS = 6\n",
    "\n",
    "DROPOUT = 0.2\n",
    "\n",
    "# Training\n",
    "EPOCHS = 40\n",
    "CHECKPOINT_FREQ = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477
    },
    "id": "YklOd1WPIbr2",
    "outputId": "7c097be5-ee6c-4106-c90b-2b11634e8543",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vasilij alexejevic nebenzja</td>\n",
       "      <td>wassili alexejewitsch nebensja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vasilij nebenzia</td>\n",
       "      <td>vassili nebenzia#vasily nebenzya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vasily nebenzya</td>\n",
       "      <td>vassili nebenzia#vasilij nebenzia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vassili nebenzia</td>\n",
       "      <td>vasilij nebenzia#vasily nebenzya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wassili alexejewitsch nebensja</td>\n",
       "      <td>vasilij alexejevic nebenzja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230799</th>\n",
       "      <td>william chappell mlajsi</td>\n",
       "      <td>william chappell, jr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230800</th>\n",
       "      <td>william chappell, jr.</td>\n",
       "      <td>william chappell mlajsi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230809</th>\n",
       "      <td>jean-laurent cochet</td>\n",
       "      <td>jean laurent cochet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230813</th>\n",
       "      <td>buckwheat zydeco</td>\n",
       "      <td>stanley dural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230814</th>\n",
       "      <td>stanley dural</td>\n",
       "      <td>buckwheat zydeco</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>669790 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  input                             target\n",
       "2           vasilij alexejevic nebenzja     wassili alexejewitsch nebensja\n",
       "3                      vasilij nebenzia   vassili nebenzia#vasily nebenzya\n",
       "4                       vasily nebenzya  vassili nebenzia#vasilij nebenzia\n",
       "5                      vassili nebenzia   vasilij nebenzia#vasily nebenzya\n",
       "6        wassili alexejewitsch nebensja        vasilij alexejevic nebenzja\n",
       "...                                 ...                                ...\n",
       "2230799         william chappell mlajsi              william chappell, jr.\n",
       "2230800           william chappell, jr.            william chappell mlajsi\n",
       "2230809             jean-laurent cochet                jean laurent cochet\n",
       "2230813                buckwheat zydeco                      stanley dural\n",
       "2230814                   stanley dural                   buckwheat zydeco\n",
       "\n",
       "[669790 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pairs_df = pd.read_csv(jrc_file, sep='|', encoding='utf-8')[['input', 'target']]\n",
    "# pairs_df = pairs_df[(pairs_df['input'].str.len() <= MAX_SEQ_LENGTH) & (pairs_df['target'].str.len() <= MAX_SEQ_LENGTH)]\n",
    "# print('Number of JRC pairs:', len(pairs_df))\n",
    "# pairs_df2 = pd.read_csv(wikidata_file, sep='|', encoding='utf-8')[['input', 'target']]\n",
    "# pairs_df2 = pairs_df2[(pairs_df2['input'].str.len() <= MAX_SEQ_LENGTH) & (pairs_df2['target'].str.len() <= MAX_SEQ_LENGTH)]\n",
    "# print('Number of Wikidata pairs:', len(pairs_df2), '\\n')\n",
    "# pairs_df = pd.concat([pairs_df, pairs_df2]).sample(frac=1, random_state=RANDOM_STATE)\n",
    "\n",
    "pairs_df = pd.read_csv(wikidata_file, sep='|', encoding='utf-8')[['input', 'target']]\n",
    "pairs_df = pairs_df[(pairs_df['input'].str.len() <= MAX_ENCODER_SEQ_LENGTH) & (pairs_df['target'].str.len() <= MAX_DECODER_SEQ_LENGTH)]\n",
    "pairs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "bKGmIus7UwPf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-28 10:18:41.215420: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-28 10:18:41.215815: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-28 10:18:41.216027: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-28 10:18:41.676617: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-28 10:18:41.676835: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-28 10:18:41.676846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-05-28 10:18:41.676982: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-28 10:18:41.677011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9509 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "encoder_dce = DictionaryCharacterEncoder(max_seq_length=MAX_ENCODER_SEQ_LENGTH+2)\n",
    "decoder_dce = DictionaryCharacterEncoder(charset='simple_with_sep', max_seq_length=MAX_DECODER_SEQ_LENGTH+2)\n",
    "\n",
    "train_batches, val_batches = prepare_asymmetric_batches(pairs_df, encoder_dce, decoder_dce, NUM_SAMPLES, VALIDATION_SPLIT, BATCH_SIZE, RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OmIgN6LG6yf2",
    "outputId": "32bf90fd-4a8c-4e1f-a58a-383bf2e5b64a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder inputs shape: (64, 31)\n",
      "Decoder inputs shape: (64, 119)\n",
      "Targets shape: (64, 119)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-28 10:19:04.051745: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant and shape [350000]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-28 10:19:04.051984: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant and shape [350000]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_batches.take(1):\n",
    "    print(f'Encoder inputs shape: {inputs[0].shape}')\n",
    "    print(f'Decoder inputs shape: {inputs[1].shape}')\n",
    "    print(f'Targets shape: {targets.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHdL_iLmSDzu"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "BpByow45PShR"
   },
   "outputs": [],
   "source": [
    "transformer = construct_asymmetric_model_w_teacher_forcing(\n",
    "    num_encoder_layers=NUM_ENCODER_LAYERS, \n",
    "    num_decoder_layers=NUM_DECODER_LAYERS, \n",
    "    encoder_unique_tokens=len(encoder_dce.charset),\n",
    "    decoder_unique_tokens=len(decoder_dce.charset),\n",
    "    max_encoder_seq_length=MAX_ENCODER_SEQ_LENGTH,\n",
    "    max_decoder_seq_length=MAX_DECODER_SEQ_LENGTH,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    intermediate_dim=INTERMEDIATE_DIM,\n",
    "    encoder_heads=NUM_ENCODER_HEADS,\n",
    "    decoder_heads=NUM_DECODER_HEADS,\n",
    "    dropout=DROPOUT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T3kmpRcNAkwP",
    "outputId": "1c327bc0-0a3a-4dab-f77e-609ced22fa03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer_w_tf\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_inputs (InputLayer)    [(None, 32)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 32, 128)      4352        ['encoder_inputs[0][0]']         \n",
      "                                                                                                  \n",
      " position_embedding (PositionEm  (None, 32, 128)     4096        ['embedding[0][0]']              \n",
      " bedding)                                                                                         \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 32, 128)     0           ['embedding[0][0]',              \n",
      " da)                                                              'position_embedding[0][0]']     \n",
      "                                                                                                  \n",
      " transformer_encoder (Transform  (None, 32, 128)     198272      ['tf.__operators__.add[0][0]']   \n",
      " erEncoder)                                                                                       \n",
      "                                                                                                  \n",
      " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " transformer_encoder_1 (Transfo  (None, 32, 128)     198272      ['transformer_encoder[0][0]']    \n",
      " rmerEncoder)                                                                                     \n",
      "                                                                                                  \n",
      " model_1 (Functional)           (None, None, 35)     1612067     ['decoder_inputs[0][0]',         \n",
      "                                                                  'transformer_encoder_1[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,017,059\n",
      "Trainable params: 2,017,059\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer.summary()\n",
    "# transformer.compile(\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "transformer.compile(\n",
    "    loss=masked_loss,\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[masked_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ERhizpGkSJk3"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "cWryJFxCQV1C"
   },
   "outputs": [],
   "source": [
    "steps_per_epoch = len(train_batches)\n",
    "\n",
    "checkpoint_path = f'{model_serialization_path}/checkpoints/' + 'weights-{epoch:03d}'\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "                checkpoint_path, \n",
    "                monitor='val_masked_accuracy', \n",
    "                save_weights_only=True,\n",
    "                save_freq=int(steps_per_epoch * CHECKPOINT_FREQ), \n",
    "                verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nt1YvG8oAn2_",
    "outputId": "72149364-17e7-4d64-eba3-5bd01a3247fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-28 10:19:05.692410: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant and shape [350000]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-28 10:19:05.692615: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant and shape [350000]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-28 10:19:14.706387: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-05-28 10:19:15.022771: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x6abca60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-05-28 10:19:15.022799: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2023-05-28 10:19:15.025802: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-05-28 10:19:15.126939: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-05-28 10:19:15.196869: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5469/5469 [==============================] - ETA: 0s - loss: 0.9468 - masked_accuracy: 0.7330"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-28 10:27:12.716479: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype variant and shape [150000]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-05-28 10:27:12.716773: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant and shape [150000]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5469/5469 [==============================] - 568s 100ms/step - loss: 0.9468 - masked_accuracy: 0.7330 - val_loss: 0.6070 - val_masked_accuracy: 0.8202\n",
      "Epoch 2/40\n",
      "5469/5469 [==============================] - 547s 100ms/step - loss: 0.6273 - masked_accuracy: 0.8148 - val_loss: 0.5476 - val_masked_accuracy: 0.8339\n",
      "Epoch 3/40\n",
      "5469/5469 [==============================] - 547s 100ms/step - loss: 0.5824 - masked_accuracy: 0.8254 - val_loss: 0.5194 - val_masked_accuracy: 0.8411\n",
      "Epoch 4/40\n",
      "5469/5469 [==============================] - 546s 100ms/step - loss: 0.5574 - masked_accuracy: 0.8314 - val_loss: 0.5005 - val_masked_accuracy: 0.8461\n",
      "Epoch 5/40\n",
      "5468/5469 [============================>.] - ETA: 0s - loss: 0.5408 - masked_accuracy: 0.8354\n",
      "Epoch 5: saving model to /thesis/models/transformer_wikidata_variant_list_1/checkpoints/weights-005\n",
      "5469/5469 [==============================] - 547s 100ms/step - loss: 0.5409 - masked_accuracy: 0.8354 - val_loss: 0.4883 - val_masked_accuracy: 0.8486\n",
      "Epoch 6/40\n",
      "5469/5469 [==============================] - 547s 100ms/step - loss: 0.5292 - masked_accuracy: 0.8383 - val_loss: 0.4787 - val_masked_accuracy: 0.8511\n",
      "Epoch 7/40\n",
      "5469/5469 [==============================] - 548s 100ms/step - loss: 0.5202 - masked_accuracy: 0.8407 - val_loss: 0.4743 - val_masked_accuracy: 0.8525\n",
      "Epoch 8/40\n",
      "5469/5469 [==============================] - 547s 100ms/step - loss: 0.5135 - masked_accuracy: 0.8423 - val_loss: 0.4654 - val_masked_accuracy: 0.8547\n",
      "Epoch 9/40\n",
      "5469/5469 [==============================] - 549s 100ms/step - loss: 0.5076 - masked_accuracy: 0.8437 - val_loss: 0.4626 - val_masked_accuracy: 0.8551\n",
      "Epoch 10/40\n",
      "5468/5469 [============================>.] - ETA: 0s - loss: 0.5029 - masked_accuracy: 0.8450\n",
      "Epoch 10: saving model to /thesis/models/transformer_wikidata_variant_list_1/checkpoints/weights-010\n",
      "5469/5469 [==============================] - 547s 100ms/step - loss: 0.5030 - masked_accuracy: 0.8450 - val_loss: 0.4603 - val_masked_accuracy: 0.8560\n",
      "Epoch 11/40\n",
      "5469/5469 [==============================] - 547s 100ms/step - loss: 0.4988 - masked_accuracy: 0.8461 - val_loss: 0.4572 - val_masked_accuracy: 0.8570\n",
      "Epoch 12/40\n",
      "5469/5469 [==============================] - 548s 100ms/step - loss: 0.4958 - masked_accuracy: 0.8468 - val_loss: 0.4536 - val_masked_accuracy: 0.8582\n",
      "Epoch 13/40\n",
      "5469/5469 [==============================] - 548s 100ms/step - loss: 0.4923 - masked_accuracy: 0.8476 - val_loss: 0.4496 - val_masked_accuracy: 0.8589\n",
      "Epoch 14/40\n",
      "5469/5469 [==============================] - 548s 100ms/step - loss: 0.4898 - masked_accuracy: 0.8482 - val_loss: 0.4476 - val_masked_accuracy: 0.8593\n",
      "Epoch 15/40\n",
      "5468/5469 [============================>.] - ETA: 0s - loss: 0.4874 - masked_accuracy: 0.8489\n",
      "Epoch 15: saving model to /thesis/models/transformer_wikidata_variant_list_1/checkpoints/weights-015\n",
      "5469/5469 [==============================] - 549s 100ms/step - loss: 0.4874 - masked_accuracy: 0.8489 - val_loss: 0.4458 - val_masked_accuracy: 0.8600\n",
      "Epoch 16/40\n",
      "5469/5469 [==============================] - 548s 100ms/step - loss: 0.4853 - masked_accuracy: 0.8493 - val_loss: 0.4449 - val_masked_accuracy: 0.8599\n",
      "Epoch 17/40\n",
      "5469/5469 [==============================] - 548s 100ms/step - loss: 0.4832 - masked_accuracy: 0.8499 - val_loss: 0.4424 - val_masked_accuracy: 0.8610\n",
      "Epoch 18/40\n",
      "5469/5469 [==============================] - 550s 100ms/step - loss: 0.4815 - masked_accuracy: 0.8503 - val_loss: 0.4412 - val_masked_accuracy: 0.8609\n",
      "Epoch 19/40\n",
      "5469/5469 [==============================] - 549s 100ms/step - loss: 0.4797 - masked_accuracy: 0.8509 - val_loss: 0.4400 - val_masked_accuracy: 0.8615\n",
      "Epoch 20/40\n",
      "5468/5469 [============================>.] - ETA: 0s - loss: 0.4781 - masked_accuracy: 0.8514\n",
      "Epoch 20: saving model to /thesis/models/transformer_wikidata_variant_list_1/checkpoints/weights-020\n",
      "5469/5469 [==============================] - 549s 100ms/step - loss: 0.4781 - masked_accuracy: 0.8514 - val_loss: 0.4402 - val_masked_accuracy: 0.8613\n",
      "Epoch 21/40\n",
      "5469/5469 [==============================] - 548s 100ms/step - loss: 0.4768 - masked_accuracy: 0.8517 - val_loss: 0.4394 - val_masked_accuracy: 0.8622\n",
      "Epoch 22/40\n",
      "5469/5469 [==============================] - 548s 100ms/step - loss: 0.4754 - masked_accuracy: 0.8520 - val_loss: 0.4376 - val_masked_accuracy: 0.8619\n",
      "Epoch 23/40\n",
      "5469/5469 [==============================] - 549s 100ms/step - loss: 0.4742 - masked_accuracy: 0.8523 - val_loss: 0.4363 - val_masked_accuracy: 0.8628\n",
      "Epoch 24/40\n",
      "5469/5469 [==============================] - 549s 100ms/step - loss: 0.4726 - masked_accuracy: 0.8527 - val_loss: 0.4348 - val_masked_accuracy: 0.8629\n",
      "Epoch 25/40\n",
      "5468/5469 [============================>.] - ETA: 0s - loss: 0.4718 - masked_accuracy: 0.8530\n",
      "Epoch 25: saving model to /thesis/models/transformer_wikidata_variant_list_1/checkpoints/weights-025\n",
      "5469/5469 [==============================] - 548s 100ms/step - loss: 0.4718 - masked_accuracy: 0.8530 - val_loss: 0.4347 - val_masked_accuracy: 0.8629\n",
      "Epoch 26/40\n",
      "5469/5469 [==============================] - 549s 100ms/step - loss: 0.4708 - masked_accuracy: 0.8532 - val_loss: 0.4315 - val_masked_accuracy: 0.8636\n",
      "Epoch 27/40\n",
      "5469/5469 [==============================] - 549s 100ms/step - loss: 0.4696 - masked_accuracy: 0.8535 - val_loss: 0.4326 - val_masked_accuracy: 0.8640\n",
      "Epoch 28/40\n",
      "5469/5469 [==============================] - 548s 100ms/step - loss: 0.4688 - masked_accuracy: 0.8537 - val_loss: 0.4348 - val_masked_accuracy: 0.8629\n",
      "Epoch 29/40\n",
      "5469/5469 [==============================] - 547s 100ms/step - loss: 0.4677 - masked_accuracy: 0.8539 - val_loss: 0.4324 - val_masked_accuracy: 0.8630\n",
      "Epoch 30/40\n",
      "5468/5469 [============================>.] - ETA: 0s - loss: 0.4669 - masked_accuracy: 0.8542\n",
      "Epoch 30: saving model to /thesis/models/transformer_wikidata_variant_list_1/checkpoints/weights-030\n",
      "5469/5469 [==============================] - 549s 100ms/step - loss: 0.4669 - masked_accuracy: 0.8542 - val_loss: 0.4321 - val_masked_accuracy: 0.8641\n",
      "Epoch 31/40\n",
      "5469/5469 [==============================] - 548s 100ms/step - loss: 0.4662 - masked_accuracy: 0.8543 - val_loss: 0.4291 - val_masked_accuracy: 0.8643\n",
      "Epoch 32/40\n",
      "5469/5469 [==============================] - 549s 100ms/step - loss: 0.4652 - masked_accuracy: 0.8545 - val_loss: 0.4277 - val_masked_accuracy: 0.8648\n",
      "Epoch 33/40\n",
      "5469/5469 [==============================] - 548s 100ms/step - loss: 0.4647 - masked_accuracy: 0.8548 - val_loss: 0.4293 - val_masked_accuracy: 0.8643\n",
      "Epoch 34/40\n",
      "5469/5469 [==============================] - 549s 100ms/step - loss: 0.4641 - masked_accuracy: 0.8549 - val_loss: 0.4255 - val_masked_accuracy: 0.8648\n",
      "Epoch 35/40\n",
      "5468/5469 [============================>.] - ETA: 0s - loss: 0.4636 - masked_accuracy: 0.8550\n",
      "Epoch 35: saving model to /thesis/models/transformer_wikidata_variant_list_1/checkpoints/weights-035\n",
      "5469/5469 [==============================] - 549s 100ms/step - loss: 0.4636 - masked_accuracy: 0.8550 - val_loss: 0.4275 - val_masked_accuracy: 0.8645\n",
      "Epoch 36/40\n",
      "5469/5469 [==============================] - 548s 100ms/step - loss: 0.4626 - masked_accuracy: 0.8552 - val_loss: 0.4288 - val_masked_accuracy: 0.8641\n",
      "Epoch 37/40\n",
      "5469/5469 [==============================] - 549s 100ms/step - loss: 0.4622 - masked_accuracy: 0.8553 - val_loss: 0.4264 - val_masked_accuracy: 0.8653\n",
      "Epoch 38/40\n",
      "5469/5469 [==============================] - 547s 100ms/step - loss: 0.4613 - masked_accuracy: 0.8557 - val_loss: 0.4301 - val_masked_accuracy: 0.8648\n",
      "Epoch 39/40\n",
      "5469/5469 [==============================] - 548s 100ms/step - loss: 0.4611 - masked_accuracy: 0.8556 - val_loss: 0.4271 - val_masked_accuracy: 0.8652\n",
      "Epoch 40/40\n",
      "5468/5469 [============================>.] - ETA: 0s - loss: 0.4607 - masked_accuracy: 0.8557\n",
      "Epoch 40: saving model to /thesis/models/transformer_wikidata_variant_list_1/checkpoints/weights-040\n",
      "5469/5469 [==============================] - 548s 100ms/step - loss: 0.4607 - masked_accuracy: 0.8557 - val_loss: 0.4252 - val_masked_accuracy: 0.8653\n"
     ]
    }
   ],
   "source": [
    "history = transformer.fit(train_batches, epochs=EPOCHS, validation_data=val_batches, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mquhrVPYRMhY",
    "outputId": "8c253fb1-a777-46dc-d85d-876a8ffaefa3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-28 16:24:52.362643: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-28 16:24:52.372394: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-28 16:24:52.382666: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-28 16:24:52.393277: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-28 16:24:52.404193: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-28 16:24:52.415241: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-28 16:24:52.424883: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-28 16:24:52.435680: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-28 16:24:52.445927: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-28 16:24:52.456603: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-28 16:24:52.468878: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-28 16:24:52.479798: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-28 16:24:52.490101: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-28 16:24:52.494962: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-28 16:24:53.097842: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,32,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-28 16:24:55.434320: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,32,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-28 16:24:56.813528: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-28 16:24:56.829581: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-28 16:24:56.839784: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-28 16:24:56.986517: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-28 16:24:56.995642: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-28 16:24:57.143732: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-28 16:24:57.153185: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-28 16:24:57.299867: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-28 16:24:57.309771: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-28 16:24:57.461723: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-28 16:24:57.471314: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-28 16:24:57.624386: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-28 16:24:57.633413: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_sequence' with dtype float and shape [?,?,128]\n",
      "\t [[{{node decoder_sequence}}]]\n",
      "2023-05-28 16:24:57.776673: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,128]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as multi_head_attention_layer_call_fn, multi_head_attention_layer_call_and_return_conditional_losses, layer_normalization_layer_call_fn, layer_normalization_layer_call_and_return_conditional_losses, dropout_1_layer_call_fn while saving (showing 5 of 316). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /thesis/models/transformer_wikidata_variant_list_1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /thesis/models/transformer_wikidata_variant_list_1/assets\n"
     ]
    }
   ],
   "source": [
    "transformer.save(f'{model_serialization_path}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "eVenfcXpVDXs"
   },
   "outputs": [],
   "source": [
    "with open(model_serialization_path + '/train_history.p', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)\n",
    "\n",
    "train_config = {\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'epochs': EPOCHS,\n",
    "    'num_samples': NUM_SAMPLES,\n",
    "    'max_seq_length': (MAX_ENCODER_SEQ_LENGTH, MAX_DECODER_SEQ_LENGTH),\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'validation_split': VALIDATION_SPLIT,\n",
    "    'encoder_layers': NUM_ENCODER_LAYERS,\n",
    "    'decoder_layers': NUM_DECODER_LAYERS,\n",
    "    'encoder_heads': NUM_ENCODER_HEADS,\n",
    "    'decoder_heads': NUM_DECODER_HEADS,\n",
    "    'dropout': DROPOUT,\n",
    "    'embedding_dim': EMBEDDING_DIM,\n",
    "    'intermediate_dim': INTERMEDIATE_DIM\n",
    "}\n",
    "\n",
    "with open(model_serialization_path + '/config.p', 'wb') as file_pi:\n",
    "    pickle.dump(train_config, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "3P4ZZWOi9Hl_"
   },
   "outputs": [],
   "source": [
    "transformer = tf.keras.models.load_model(f'{model_serialization_path}/', custom_objects={'masked_loss': masked_loss, 'masked_accuracy': masked_accuracy})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMBywO57SNO8"
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vTCtzqJWElIR",
    "outputId": "b9a2bc41-949b-40a4-ad6d-f357009f13c4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samuel meyer\n",
      "samuel meyer#samuel meyer\n",
      "\n",
      "dmitry medvedev\n",
      "dmitrij medvedev#dmitrij medvedev#dmitrij medvedev#dmitrij medvedev#dmitrij medvedev\n",
      "\n",
      "paulo ricardo\n",
      "paulus ricardus\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def decode_sequences(input_sentence):\n",
    "     # Tokenize the encoder input.\n",
    "    encoder_input_tokens = tf.keras.utils.pad_sequences(\n",
    "        encoder_dce.to_ids([input_sentence], insert_markers=True), \n",
    "        padding='post', \n",
    "        maxlen=MAX_ENCODER_SEQ_LENGTH+2\n",
    "    )\n",
    "\n",
    "    # Define a function that outputs the next token's probability given the\n",
    "    # input sequence.\n",
    "    def token_probability_fn(decoder_input_tokens):\n",
    "        return transformer([encoder_input_tokens, decoder_input_tokens])[:, -1, :]\n",
    "\n",
    "\n",
    "    prompt = tf.fill((1, 1), decoder_dce.char_index['\\t'])\n",
    "    generated_tokens = keras_nlp.utils.top_p_search(\n",
    "        token_probability_fn,\n",
    "        prompt,\n",
    "        p=0.1,\n",
    "        max_length=MAX_DECODER_SEQ_LENGTH,\n",
    "        end_token_id=decoder_dce.char_index['\\n'],\n",
    "    )\n",
    "    generated_sentences = ''.join([decoder_dce.inverse_char_index[tkn] for tkn in generated_tokens.numpy()[0]])\n",
    "    return generated_sentences.strip()\n",
    "\n",
    "names = [\n",
    "    'samuel meyer',\n",
    "    'dmitry medvedev',\n",
    "    'paulo ricardo',\n",
    "    'zouheir al qaissi',\n",
    "    'tarek al bichri',\n",
    "    'thorsten brotzmann'\n",
    "]\n",
    "\n",
    "for s in names:\n",
    "    translated = decode_sequences(s)\n",
    "    print(s)\n",
    "    print(translated)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "224e0c0e73d638a3e6069c377694d7b3b3236453c6483b31fd1a6425297d86e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
