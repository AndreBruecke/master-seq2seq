{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/thesis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fP7ayWracqNh",
    "outputId": "de1a156b-1580-4a3a-ef71-2ce743791f5d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-02 14:13:24.877901: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-02 14:13:24.926880: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-02 14:13:26.333720: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-02 14:13:26.348596: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-02 14:13:26.348997: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "import logging\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from helper.character_encoder import DictionaryCharacterEncoder\n",
    "from helper.prediction import predict_sequence\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xePXGXM_cWrl"
   },
   "outputs": [],
   "source": [
    "# Input file paths\n",
    "jrc_file = '/thesis/data/jrc_person_pairs.csv'\n",
    "wikidata_file = '/thesis/data/wikidata_person_pairs.csv'\n",
    "\n",
    "model_serialization_path = '/thesis/models/new'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PP58W4r4UVo"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "SMRA3no_-amU"
   },
   "outputs": [],
   "source": [
    "max_sample_seq_length = 30  # 40\n",
    "num_samples = 550000\n",
    "epochs = 12\n",
    "\n",
    "random_state = 1010\n",
    "validation_split = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "id": "YklOd1WPIbr2",
    "outputId": "471f4b44-db7a-40f0-81ab-ec4964c12e74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of JRC pairs 131636\n",
      "Number of WikiData pairs 434230 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>272102</th>\n",
       "      <td>katharine mccook knox</td>\n",
       "      <td>katherine mccook knox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431611</th>\n",
       "      <td>meri aroni</td>\n",
       "      <td>mary aroni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61867</th>\n",
       "      <td>alejandro foxley</td>\n",
       "      <td>alejandre foxley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424660</th>\n",
       "      <td>niche perez</td>\n",
       "      <td>limber perez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244085</th>\n",
       "      <td>jindrich wankel</td>\n",
       "      <td>heinrich wankel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440185</th>\n",
       "      <td>vitaly lisakovich</td>\n",
       "      <td>vital' lisakovic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122954</th>\n",
       "      <td>adam vojtech</td>\n",
       "      <td>adama vojtecha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27211</th>\n",
       "      <td>david petraeus</td>\n",
       "      <td>david petreaeus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164783</th>\n",
       "      <td>ethel standiford-mehling</td>\n",
       "      <td>ethel standiford-mehlingan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108526</th>\n",
       "      <td>magdalen herbert</td>\n",
       "      <td>magdalen newport</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>565866 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           input                      target\n",
       "272102     katharine mccook knox       katherine mccook knox\n",
       "431611                meri aroni                  mary aroni\n",
       "61867           alejandro foxley            alejandre foxley\n",
       "424660               niche perez                limber perez\n",
       "244085           jindrich wankel             heinrich wankel\n",
       "...                          ...                         ...\n",
       "440185         vitaly lisakovich            vital' lisakovic\n",
       "122954              adam vojtech              adama vojtecha\n",
       "27211             david petraeus             david petreaeus\n",
       "164783  ethel standiford-mehling  ethel standiford-mehlingan\n",
       "108526          magdalen herbert            magdalen newport\n",
       "\n",
       "[565866 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_df = pd.read_csv(jrc_file, sep='|', encoding='utf-8')[['input', 'target']]\n",
    "pairs_df = pairs_df[(pairs_df['input'].str.len() <= max_sample_seq_length) & (pairs_df['target'].str.len() <= max_sample_seq_length)]\n",
    "print('Number of JRC pairs', len(pairs_df))\n",
    "pairs_df2 = pd.read_csv(wikidata_file, sep='|', encoding='utf-8')[['input', 'target']]\n",
    "pairs_df2 = pairs_df2[(pairs_df2['input'].str.len() <= max_sample_seq_length) & (pairs_df2['target'].str.len() <= max_sample_seq_length)]\n",
    "print('Number of WikiData pairs', len(pairs_df2), '\\n')\n",
    "\n",
    "pairs_df = pd.concat([pairs_df, pairs_df2]).sample(frac=1, random_state=random_state)\n",
    "pairs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "28W13EVH33wI"
   },
   "outputs": [],
   "source": [
    "# Sample training data and retrieve the vectorized representation\n",
    "train_smpl = pairs_df.sample(num_samples, random_state=random_state)\n",
    "val_smpl = train_smpl.sample(frac=validation_split, random_state=random_state)\n",
    "train_smpl = train_smpl.drop(val_smpl.index)\n",
    "\n",
    "dce = DictionaryCharacterEncoder(max_seq_length=max_sample_seq_length+2)\n",
    "\n",
    "train_input = train_smpl['input'].tolist()\n",
    "train_target = train_smpl['target'].tolist()\n",
    "\n",
    "val_input = val_smpl['input'].tolist()\n",
    "val_target = val_smpl['target'].tolist()\n",
    "\n",
    "train_input_ids = dce.to_ids(train_input, insert_markers=True)\n",
    "train_target_ids = dce.to_ids(train_target, insert_markers=True)\n",
    "\n",
    "val_input_ids = dce.to_ids(val_input, insert_markers=True)\n",
    "val_target_ids = dce.to_ids(val_target, insert_markers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "W5FWnSiRmdgc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-02 14:13:37.717392: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-02 14:13:37.718041: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-02 14:13:37.718746: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-02 14:13:38.354464: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-02 14:13:38.354731: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-02 14:13:38.354741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-05-02 14:13:38.354911: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-02 14:13:38.354957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9509 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "train_input_tensors = tf.ragged.constant(train_input_ids)\n",
    "train_target_tensors = tf.ragged.constant(train_target_ids)\n",
    "\n",
    "val_input_tensors = tf.ragged.constant(val_input_ids)\n",
    "val_target_tensors = tf.ragged.constant(val_target_ids)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_input_tensors, train_target_tensors))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_input_tensors, val_target_tensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "6shgzEck3FiV"
   },
   "outputs": [],
   "source": [
    "def prepare_batch_char(input, target):\n",
    "    input = input[:, :dce.max_seq_length]\n",
    "    input = input.to_tensor()  # Convert to 0-padded dense Tensor\n",
    "\n",
    "    target = target[:, :(dce.max_seq_length+1)]\n",
    "    target_inputs = target[:, :-1].to_tensor()  # Drop the [END] tokens\n",
    "    target_labels = target[:, 1:].to_tensor()   # Drop the [START] tokens\n",
    "\n",
    "    return (input, target_inputs), target_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "bcRp7VcQ5m6g"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BUN_jLBTwNxk"
   },
   "outputs": [],
   "source": [
    "def make_batches_char(ds):\n",
    "  return (\n",
    "      ds\n",
    "      .shuffle(BUFFER_SIZE)\n",
    "      .batch(BATCH_SIZE)\n",
    "      .map(prepare_batch_char, tf.data.AUTOTUNE)\n",
    "      .prefetch(buffer_size=tf.data.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "itSWqk-ivrRg"
   },
   "source": [
    "## Test the Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "OgB8-9kdqT7e"
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.prefetch(BUFFER_SIZE)\n",
    "val_dataset = val_dataset.prefetch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "BSswr5TKvoNM"
   },
   "outputs": [],
   "source": [
    "# Create training and validation set batches.\n",
    "train_batches = make_batches_char(train_dataset)\n",
    "val_batches = make_batches_char(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YS75Y-9-lkzn"
   },
   "source": [
    "### The embedding and positional encoding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1Rz82wEs5biZ"
   },
   "outputs": [],
   "source": [
    "def positional_encoding(length, depth):\n",
    "  depth = depth/2\n",
    "\n",
    "  positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
    "  depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
    "  \n",
    "  angle_rates = 1 / (10000**depths)         # (1, depth)\n",
    "  angle_rads = positions * angle_rates      # (pos, depth)\n",
    "\n",
    "  pos_encoding = np.concatenate(\n",
    "      [np.sin(angle_rads), np.cos(angle_rads)],\n",
    "      axis=-1) \n",
    "\n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "838tmM1cm9cB"
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "  def __init__(self, vocab_size, d_model):\n",
    "    super().__init__()\n",
    "    self.d_model = d_model\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True) \n",
    "    self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
    "\n",
    "  def compute_mask(self, *args, **kwargs):\n",
    "    return self.embedding.compute_mask(*args, **kwargs)\n",
    "\n",
    "  def call(self, x):\n",
    "    length = tf.shape(x)[1]\n",
    "    x = self.embedding(x)\n",
    "    # This factor sets the relative scale of the embedding and positonal_encoding.\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJAJ2_VlPXrZ"
   },
   "source": [
    "### The base attention layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "5VLa5QcdPpv5"
   },
   "outputs": [],
   "source": [
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, **kwargs):\n",
    "    super().__init__()\n",
    "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "    self.add = tf.keras.layers.Add()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7QcPJvmv6ix"
   },
   "source": [
    "### The cross attention layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "kfHVbJUWv8qp"
   },
   "outputs": [],
   "source": [
    "class CrossAttention(BaseAttention):\n",
    "  def call(self, x, context):\n",
    "    attn_output, attn_scores = self.mha(\n",
    "        query=x,\n",
    "        key=context,\n",
    "        value=context,\n",
    "        return_attention_scores=True)\n",
    "   \n",
    "    # Cache the attention scores for plotting later.\n",
    "    self.last_attn_scores = attn_scores\n",
    "\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6qrQxSpv34R"
   },
   "source": [
    "### The global self attention layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "RNqoTpn1wB3i"
   },
   "outputs": [],
   "source": [
    "class GlobalSelfAttention(BaseAttention):\n",
    "  def call(self, x):\n",
    "    attn_output = self.mha(\n",
    "        query=x,\n",
    "        value=x,\n",
    "        key=x)\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yq4NtLymD99-"
   },
   "source": [
    "### The causal self attention layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "4MMQ-AfKD99_"
   },
   "outputs": [],
   "source": [
    "class CausalSelfAttention(BaseAttention):\n",
    "  def call(self, x):\n",
    "    attn_output = self.mha(\n",
    "        query=x,\n",
    "        value=x,\n",
    "        key=x,\n",
    "        use_causal_mask = True)\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLjScSWQv9M5"
   },
   "source": [
    "### The feed forward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "rAYLeu0uwXYK"
   },
   "outputs": [],
   "source": [
    "class FeedForward(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, dff, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.seq = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),\n",
    "      tf.keras.layers.Dense(d_model),\n",
    "      tf.keras.layers.Dropout(dropout_rate)\n",
    "    ])\n",
    "    self.add = tf.keras.layers.Add()\n",
    "    self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.add([x, self.seq(x)])\n",
    "    x = self.layer_norm(x) \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFv-FNYUmvpn"
   },
   "source": [
    "### The encoder layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ncyS-Ms3i2x_"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.self_attention = GlobalSelfAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.self_attention(x)\n",
    "    x = self.ffn(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SE1H51Ajm0q1"
   },
   "source": [
    "### The encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "jpEox7gJ8FCI"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads,\n",
    "               dff, vocab_size, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.pos_embedding = PositionalEmbedding(\n",
    "        vocab_size=vocab_size, d_model=d_model)\n",
    "\n",
    "    self.enc_layers = [\n",
    "        EncoderLayer(d_model=d_model,\n",
    "                     num_heads=num_heads,\n",
    "                     dff=dff,\n",
    "                     dropout_rate=dropout_rate)\n",
    "        for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "  def call(self, x):\n",
    "    # `x` is token-IDs shape: (batch, seq_len)\n",
    "    x = self.pos_embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "    \n",
    "    # Add dropout.\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x)\n",
    "\n",
    "    return x  # Shape `(batch_size, seq_len, d_model)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LO_48Owmx_o"
   },
   "source": [
    "### The decoder layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "9SoX0-vd1hue"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self,\n",
    "               *,\n",
    "               d_model,\n",
    "               num_heads,\n",
    "               dff,\n",
    "               dropout_rate=0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "\n",
    "    self.causal_self_attention = CausalSelfAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "    \n",
    "    self.cross_attention = CrossAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "  def call(self, x, context):\n",
    "    x = self.causal_self_attention(x=x)\n",
    "    x = self.cross_attention(x=x, context=context)\n",
    "\n",
    "    # Cache the last attention scores for plotting later\n",
    "    self.last_attn_scores = self.cross_attention.last_attn_scores\n",
    "\n",
    "    x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-uO6ls8m2O5"
   },
   "source": [
    "### The decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "d5_d5-PLQXwY"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size,\n",
    "               dropout_rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size,\n",
    "                                             d_model=d_model)\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "    self.dec_layers = [\n",
    "        DecoderLayer(d_model=d_model, num_heads=num_heads,\n",
    "                     dff=dff, dropout_rate=dropout_rate)\n",
    "        for _ in range(num_layers)]\n",
    "\n",
    "    self.last_attn_scores = None\n",
    "\n",
    "  def call(self, x, context):\n",
    "    # `x` is token-IDs shape (batch, target_seq_len)\n",
    "    x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x  = self.dec_layers[i](x, context)\n",
    "\n",
    "    self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
    "\n",
    "    # The shape of x is (batch_size, target_seq_len, d_model).\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y54xnJnuYgJ7"
   },
   "source": [
    "## The Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "PED3bIpOYkBu"
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, *, num_enc_layers, num_dec_layers, d_model, num_heads, dff,\n",
    "               input_vocab_size, target_vocab_size, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.encoder = Encoder(num_layers=num_enc_layers, d_model=d_model,\n",
    "                           num_heads=num_heads, dff=dff,\n",
    "                           vocab_size=input_vocab_size,\n",
    "                           dropout_rate=dropout_rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers=num_dec_layers, d_model=d_model,\n",
    "                           num_heads=num_heads, dff=dff,\n",
    "                           vocab_size=target_vocab_size,\n",
    "                           dropout_rate=dropout_rate)\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    # To use a Keras model with `.fit` you must pass all your inputs in the\n",
    "    # first argument.\n",
    "    context, x  = inputs\n",
    "\n",
    "    context = self.encoder(context)  # (batch_size, context_len, d_model)\n",
    "\n",
    "    x = self.decoder(x, context)  # (batch_size, target_len, d_model)\n",
    "\n",
    "    # Final linear layer output.\n",
    "    logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n",
    "\n",
    "    try:\n",
    "      # Drop the keras mask, so it doesn't scale the losses/metrics.\n",
    "      # b/250038731\n",
    "      del logits._keras_mask\n",
    "    except AttributeError:\n",
    "      pass\n",
    "\n",
    "    # Return the final output and the attention weights.\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wsINyf1VEQLC"
   },
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IjwMq_ixlzd5"
   },
   "source": [
    "To keep this example small and relatively fast, the number of layers (`num_layers`), the dimensionality of the embeddings (`d_model`), and the internal dimensionality of the `FeedForward` layer (`dff`) have been reduced.\n",
    "\n",
    "The base model described in the original Transformer paper used `num_layers=6`, `d_model=512`, and `dff=2048`.\n",
    "\n",
    "The number of self-attention heads remains the same (`num_heads=8`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "mzyo6KDfVyhl"
   },
   "outputs": [],
   "source": [
    "num_enc_layers = 2\n",
    "num_dec_layers = 4\n",
    "d_model = 32\n",
    "dff = 512\n",
    "num_heads = 8  # 16\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "UiysUa--4tOU"
   },
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    num_enc_layers=num_enc_layers,\n",
    "    num_dec_layers=num_dec_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=len(dce.charset),\n",
    "    target_vocab_size=len(dce.charset),\n",
    "    dropout_rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfoBfC2oQtEy"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "67oqVHiT0Eiu"
   },
   "outputs": [],
   "source": [
    "def masked_loss(label, pred):\n",
    "  mask = label != 0\n",
    "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "  loss = loss_object(label, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss.dtype)\n",
    "  loss *= mask\n",
    "\n",
    "  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
    "  return loss\n",
    "\n",
    "\n",
    "def masked_accuracy(label, pred):\n",
    "  pred = tf.argmax(pred, axis=2)\n",
    "  label = tf.cast(label, pred.dtype)\n",
    "  match = label == pred\n",
    "\n",
    "  mask = label != 0\n",
    "\n",
    "  match = match & mask\n",
    "\n",
    "  match = tf.cast(match, dtype=tf.float32)\n",
    "  mask = tf.cast(mask, dtype=tf.float32)\n",
    "  return tf.reduce_sum(match)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Una1v0hDlIsT"
   },
   "outputs": [],
   "source": [
    "transformer.compile(\n",
    "    loss=masked_loss,\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[masked_accuracy])\n",
    "\n",
    "# transformer.compile(\n",
    "#    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#    optimizer=tf.keras.optimizers.Adam(),\n",
    "#    metrics=[\"accuracy\"])\n",
    "\n",
    "# loss='categorical_crossentropy', metrics=[\"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = len(train_input) / float(BATCH_SIZE)\n",
    "checkpoint_n = 2\n",
    "\n",
    "checkpoint_path = f'{model_serialization_path}/checkpoints/' + 'weights-{epoch:03d}'\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "                checkpoint_path, \n",
    "                monitor='val_masked_accuracy', \n",
    "                save_weights_only=True, \n",
    "                save_freq=int(steps_per_epoch * checkpoint_n), \n",
    "                verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jg35qKvVlctp",
    "outputId": "faad5b4c-f370-4bfb-94fc-95ecb1c2982e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-02 14:13:50.790837: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant and shape [367236]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-02 14:13:50.791081: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype variant and shape [367236]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-05-02 14:13:58.546119: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-05-02 14:13:58.720371: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-05-02 14:13:58.860295: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f43cf4ca7d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-05-02 14:13:58.860338: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2023-05-02 14:13:58.865460: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-05-02 14:13:58.971102: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5739/5739 [==============================] - ETA: 0s - loss: 1.1079 - masked_accuracy: 0.7090"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-02 14:17:15.475627: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype variant and shape [137500]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-05-02 14:17:15.475872: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype variant and shape [137500]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5739/5739 [==============================] - 243s 40ms/step - loss: 1.1079 - masked_accuracy: 0.7090 - val_loss: 0.7883 - val_masked_accuracy: 0.7946\n",
      "Epoch 2/12\n",
      "5735/5739 [============================>.] - ETA: 0s - loss: 0.7768 - masked_accuracy: 0.7963\n",
      "Epoch 2: saving model to /thesis/models/test_transformer_e3/checkpoints/weights-002\n",
      "5739/5739 [==============================] - 226s 39ms/step - loss: 0.7768 - masked_accuracy: 0.7964 - val_loss: 0.6275 - val_masked_accuracy: 0.8399\n",
      "Epoch 3/12\n",
      "5739/5739 [==============================] - 225s 39ms/step - loss: 0.6771 - masked_accuracy: 0.8248 - val_loss: 0.5729 - val_masked_accuracy: 0.8519\n",
      "Epoch 4/12\n",
      "5733/5739 [============================>.] - ETA: 0s - loss: 0.6250 - masked_accuracy: 0.8375\n",
      "Epoch 4: saving model to /thesis/models/test_transformer_e3/checkpoints/weights-004\n",
      "5739/5739 [==============================] - 229s 40ms/step - loss: 0.6250 - masked_accuracy: 0.8375 - val_loss: 0.5432 - val_masked_accuracy: 0.8581\n",
      "Epoch 5/12\n",
      "5739/5739 [==============================] - 225s 39ms/step - loss: 0.6157 - masked_accuracy: 0.8395 - val_loss: 0.5646 - val_masked_accuracy: 0.8545\n",
      "Epoch 6/12\n",
      "5731/5739 [============================>.] - ETA: 0s - loss: 0.5941 - masked_accuracy: 0.8446\n",
      "Epoch 6: saving model to /thesis/models/test_transformer_e3/checkpoints/weights-006\n",
      "5739/5739 [==============================] - 227s 40ms/step - loss: 0.5940 - masked_accuracy: 0.8446 - val_loss: 0.5222 - val_masked_accuracy: 0.8630\n",
      "Epoch 7/12\n",
      "5739/5739 [==============================] - 225s 39ms/step - loss: 0.5774 - masked_accuracy: 0.8485 - val_loss: 0.5105 - val_masked_accuracy: 0.8654\n",
      "Epoch 8/12\n",
      "5730/5739 [============================>.] - ETA: 0s - loss: 0.5697 - masked_accuracy: 0.8505\n",
      "Epoch 8: saving model to /thesis/models/test_transformer_e3/checkpoints/weights-008\n",
      "5739/5739 [==============================] - 226s 39ms/step - loss: 0.5697 - masked_accuracy: 0.8506 - val_loss: 0.5033 - val_masked_accuracy: 0.8680\n",
      "Epoch 9/12\n",
      "5739/5739 [==============================] - 227s 40ms/step - loss: 0.5572 - masked_accuracy: 0.8536 - val_loss: 0.5003 - val_masked_accuracy: 0.8680\n",
      "Epoch 10/12\n",
      "5727/5739 [============================>.] - ETA: 0s - loss: 0.5460 - masked_accuracy: 0.8563\n",
      "Epoch 10: saving model to /thesis/models/test_transformer_e3/checkpoints/weights-010\n",
      "5739/5739 [==============================] - 224s 39ms/step - loss: 0.5459 - masked_accuracy: 0.8563 - val_loss: 0.4870 - val_masked_accuracy: 0.8708\n",
      "Epoch 11/12\n",
      "5739/5739 [==============================] - 225s 39ms/step - loss: 0.5442 - masked_accuracy: 0.8566 - val_loss: 0.4802 - val_masked_accuracy: 0.8722\n",
      "Epoch 12/12\n",
      "5726/5739 [============================>.] - ETA: 0s - loss: 0.5359 - masked_accuracy: 0.8583\n",
      "Epoch 12: saving model to /thesis/models/test_transformer_e3/checkpoints/weights-012\n",
      "5739/5739 [==============================] - 227s 39ms/step - loss: 0.5360 - masked_accuracy: 0.8583 - val_loss: 0.4788 - val_masked_accuracy: 0.8724\n"
     ]
    }
   ],
   "source": [
    "history = transformer.fit(train_batches,\n",
    "                epochs=epochs,\n",
    "                validation_data=val_batches,\n",
    "                callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "JwpViBYUUn4b"
   },
   "outputs": [],
   "source": [
    "transformer.save_weights(f'{model_serialization_path}/weights')\n",
    "with open(model_serialization_path + '/train_history.p', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)\n",
    "\n",
    "train_config = {\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'epochs': epochs,\n",
    "    'num_samples': num_samples,\n",
    "    'random_state': random_state,\n",
    "    'validation_split': validation_split,\n",
    "    'encoder_layers': num_enc_layers,\n",
    "    'decoder_layers': num_dec_layers,\n",
    "    'attention_heads': num_heads,\n",
    "    'dropout': dropout_rate,\n",
    "    'd_model': d_model\n",
    "}\n",
    "\n",
    "# dff = 512\n",
    "\n",
    "with open(model_serialization_path + '/config.p', 'wb') as file_pi:\n",
    "    pickle.dump(train_config, file_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cxKpqCbzSW6z"
   },
   "source": [
    "## Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "eY_uXsOhSmbb"
   },
   "outputs": [],
   "source": [
    "class Translator(tf.Module):\n",
    "  def __init__(self, transformer):\n",
    "    self.transformer = transformer\n",
    "\n",
    "  def __call__(self, sentence):\n",
    "    sentence = tf.convert_to_tensor(dce.to_ids([sentence], insert_markers=True))\n",
    "\n",
    "    encoder_input = sentence\n",
    "\n",
    "    # As the output language is English, initialize the output with the\n",
    "    # English `[START]` token.\n",
    "    start_end = tf.convert_to_tensor([dce.char_index['\\t'], dce.char_index['\\t']], dtype=tf.int64)\n",
    "    start = start_end[0][tf.newaxis]\n",
    "    end = start_end[1][tf.newaxis]\n",
    "\n",
    "    # `tf.TensorArray` is required here (instead of a Python list), so that the\n",
    "    # dynamic-loop can be traced by `tf.function`.\n",
    "    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
    "    output_array = output_array.write(0, start)\n",
    "\n",
    "    for i in tf.range(max_sample_seq_length):\n",
    "      output = tf.transpose(output_array.stack())\n",
    "      predictions = self.transformer([encoder_input, output], training=False)\n",
    "\n",
    "      # Select the last token from the `seq_len` dimension.\n",
    "      predictions = predictions[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.\n",
    "\n",
    "      predicted_id = tf.argmax(predictions, axis=-1)\n",
    "\n",
    "      # Concatenate the `predicted_id` to the output which is given to the\n",
    "      # decoder as its input.\n",
    "      output_array = output_array.write(i+1, predicted_id[0])\n",
    "\n",
    "      if predicted_id == end:\n",
    "        break\n",
    "\n",
    "    output = tf.transpose(output_array.stack())\n",
    "    # The output shape is `(1, tokens)`.\n",
    "    # text = tokenizers.en.detokenize(output)[0]  # Shape: `()`.\n",
    "    # tokens = tokenizers.en.lookup(output)[0]\n",
    "\n",
    "    return output\n",
    "    # return text, tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "-NjbvpHUTEia"
   },
   "outputs": [],
   "source": [
    "translator = Translator(transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "o9CEm4cuTGtw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samuel meyer\n",
      "\temuel meyer  er    e   e   er \n",
      "dmitry medvedev\n",
      "\tymitri medvedev      eva      \n",
      "paulo ricardo\n",
      "\tolikardo paulo   o    a       \n",
      "zouheir al qaissi\n",
      "\tal zouheir al qaissi  on e  e \n",
      "tarek al bichri\n",
      "\tal tarek bichri      e  e     \n",
      "thorsten brotzmann\n",
      "\tathorsten brotzmann           \n"
     ]
    }
   ],
   "source": [
    "names = [\n",
    "    'samuel meyer',\n",
    "    'dmitry medvedev',\n",
    "    'paulo ricardo',\n",
    "    'zouheir al qaissi',\n",
    "    'tarek al bichri',\n",
    "    'thorsten brotzmann'\n",
    "]\n",
    "\n",
    "for name in names:\n",
    "    print(name)\n",
    "    output = translator(name)\n",
    "    for pred_id in output.numpy()[0]:\n",
    "        print(dce.inverse_char_index[pred_id] if pred_id != 1 else ' ', end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "lkWJCWMrr6Jq",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samuel meyer\n",
      "\temuel meyer  er    e   e   er \n",
      "dmitry medvedev\n",
      "\tymitri medvedev      eva      \n",
      "paulo ricardo\n",
      "\tolikardo paulo   o    a       \n",
      "zouheir al qaissi\n",
      "\tal zouheir al qaissi  on e  e \n",
      "tarek al bichri\n",
      "\tal tarek bichri      e  e     \n",
      "thorsten brotzmann\n",
      "\tathorsten brotzmann           \n"
     ]
    }
   ],
   "source": [
    "transformer = Transformer(\n",
    "    num_enc_layers=num_enc_layers,\n",
    "    num_dec_layers=num_dec_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=len(dce.charset),\n",
    "    target_vocab_size=len(dce.charset),\n",
    "    dropout_rate=dropout_rate)\n",
    "\n",
    "transformer.load_weights(f'{model_serialization_path}/weights')\n",
    "\n",
    "\n",
    "translator = Translator(transformer)\n",
    "\n",
    "names = [\n",
    "    'samuel meyer',\n",
    "    'dmitry medvedev',\n",
    "    'paulo ricardo',\n",
    "    'zouheir al qaissi',\n",
    "    'tarek al bichri',\n",
    "    'thorsten brotzmann'\n",
    "]\n",
    "\n",
    "for name in names:\n",
    "    print(name)\n",
    "    output = translator(name)\n",
    "    for pred_id in output.numpy()[0]:\n",
    "        print(dce.inverse_char_index[pred_id] if pred_id != 1 else ' ', end='')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
